{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab995bc5-a89d-4b3c-bdc4-432e3c999ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:06:19.486622Z",
     "iopub.status.busy": "2025-12-18T23:06:19.486350Z",
     "iopub.status.idle": "2025-12-18T23:06:19.494399Z",
     "shell.execute_reply": "2025-12-18T23:06:19.493842Z",
     "shell.execute_reply.started": "2025-12-18T23:06:19.486602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5f205516b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, csv, json, random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "PROJECT_ROOT = \".\"\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"Amazon_products\")\n",
    "\n",
    "TRAIN_CORPUS_PATH = os.path.join(DATA_DIR, \"train\", \"train_corpus.txt\")\n",
    "TEST_CORPUS_PATH  = os.path.join(DATA_DIR, \"test\",  \"test_corpus.txt\")\n",
    "\n",
    "CLASSES_PATH = os.path.join(DATA_DIR, \"classes.txt\")\n",
    "HIER_PATH    = os.path.join(DATA_DIR, \"class_hierarchy.txt\")\n",
    "KEYWORD_PATH = os.path.join(DATA_DIR, \"class_related_keywords.txt\")\n",
    "\n",
    "ART_DIR = os.path.join(PROJECT_ROOT, \"artifacts\")\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "NUM_CLASSES = 531\n",
    "MIN_LABELS = 2\n",
    "MAX_LABELS = 3\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e14acf8-557a-48f0-9c68-f0fc72b55566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:06:49.195733Z",
     "iopub.status.busy": "2025-12-18T23:06:49.195433Z",
     "iopub.status.idle": "2025-12-18T23:06:50.076143Z",
     "shell.execute_reply": "2025-12-18T23:06:50.075526Z",
     "shell.execute_reply.started": "2025-12-18T23:06:49.195709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 29487 test: 19658\n"
     ]
    }
   ],
   "source": [
    "# Clean + Load Corpus\n",
    "\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s or \"\"\n",
    "    s = TAG_RE.sub(\" \", s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def load_corpus(path: str):\n",
    "    pid2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                pid, text = parts\n",
    "                pid2text[pid] = clean_text(text)\n",
    "    return pid2text\n",
    "\n",
    "pid2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "pid2text_test  = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test   = list(pid2text_test.keys())\n",
    "\n",
    "print(\"train:\", len(pid2text_train), \"test:\", len(pid2text_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf4cf20-b08a-457a-b0b4-70848dc277f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:07:01.432184Z",
     "iopub.status.busy": "2025-12-18T23:07:01.431923Z",
     "iopub.status.idle": "2025-12-18T23:07:01.437801Z",
     "shell.execute_reply": "2025-12-18T23:07:01.437321Z",
     "shell.execute_reply.started": "2025-12-18T23:07:01.432165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes loaded: 531\n"
     ]
    }
   ],
   "source": [
    "def load_classes(path):\n",
    "    name2id, id2name = {}, {}\n",
    "    next_id = 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = re.split(r\"[\\t, ]+\", line)\n",
    "            if parts[0].isdigit():\n",
    "                cid = int(parts[0])\n",
    "                cname = parts[1] if len(parts) > 1 else str(cid)\n",
    "            else:\n",
    "                cid = next_id\n",
    "                cname = parts[0]\n",
    "                next_id += 1\n",
    "            name2id[cname] = cid\n",
    "            id2name[cid] = cname\n",
    "    return name2id, id2name\n",
    "\n",
    "name2id, id2name = load_classes(CLASSES_PATH)\n",
    "print(\"num classes loaded:\", len(name2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514f879f-cf74-4d6e-86db-9324a761150b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:07:14.194813Z",
     "iopub.status.busy": "2025-12-18T23:07:14.194538Z",
     "iopub.status.idle": "2025-12-18T23:07:14.203036Z",
     "shell.execute_reply": "2025-12-18T23:07:14.202534Z",
     "shell.execute_reply.started": "2025-12-18T23:07:14.194793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n"
     ]
    }
   ],
   "source": [
    "def load_hierarchy(path):\n",
    "    parents = defaultdict(set)  # child -> parents\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            p_str, c_str = line.split(\"\\t\")\n",
    "            p, c = int(p_str), int(c_str)\n",
    "            parents[c].add(p)\n",
    "    return parents\n",
    "\n",
    "parents = load_hierarchy(HIER_PATH)\n",
    "\n",
    "def get_ancestors(cid: int) -> set:\n",
    "    anc = set()\n",
    "    stack = [cid]\n",
    "    while stack:\n",
    "        x = stack.pop()\n",
    "        for p in parents.get(x, []):\n",
    "            if p not in anc:\n",
    "                anc.add(p)\n",
    "                stack.append(p)\n",
    "    return anc\n",
    "\n",
    "def compute_depths(num_classes: int):\n",
    "    depth = [-1] * num_classes\n",
    "    def dfs(x):\n",
    "        if depth[x] != -1:\n",
    "            return depth[x]\n",
    "        ps = parents.get(x, [])\n",
    "        if not ps:\n",
    "            depth[x] = 0\n",
    "            return 0\n",
    "        depth[x] = 1 + max(dfs(p) for p in ps)\n",
    "        return depth[x]\n",
    "    for i in range(num_classes):\n",
    "        dfs(i)\n",
    "    return depth\n",
    "\n",
    "depths = compute_depths(NUM_CLASSES)\n",
    "print(\"max depth:\", max(depths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb87a750-7efe-4a23-8486-4c4fb448ff2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:07:24.571247Z",
     "iopub.status.busy": "2025-12-18T23:07:24.570862Z",
     "iopub.status.idle": "2025-12-18T23:07:24.632831Z",
     "shell.execute_reply": "2025-12-18T23:07:24.632271Z",
     "shell.execute_reply.started": "2025-12-18T23:07:24.571228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_hat: torch.Size([531, 531])\n"
     ]
    }
   ],
   "source": [
    "def build_label_adj(num_classes, parents_dict, add_self_loop=True, undirected=True):\n",
    "    A = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    for child, ps in parents_dict.items():\n",
    "        for p in ps:\n",
    "            A[p, child] = 1.0\n",
    "            if undirected:\n",
    "                A[child, p] = 1.0\n",
    "    if add_self_loop:\n",
    "        np.fill_diagonal(A, 1.0)\n",
    "\n",
    "    deg = A.sum(axis=1)\n",
    "    deg_inv_sqrt = np.power(deg, -0.5, where=deg>0)\n",
    "    deg_inv_sqrt[deg == 0] = 0.0\n",
    "    D_inv_sqrt = np.diag(deg_inv_sqrt)\n",
    "    A_hat = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return torch.tensor(A_hat, dtype=torch.float32)\n",
    "\n",
    "A_hat = build_label_adj(NUM_CLASSES, parents)\n",
    "print(\"A_hat:\", A_hat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80296a73-4ebf-4a63-aa45-433a4b794c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:07:32.758547Z",
     "iopub.status.busy": "2025-12-18T23:07:32.758255Z",
     "iopub.status.idle": "2025-12-18T23:07:32.771701Z",
     "shell.execute_reply": "2025-12-18T23:07:32.771180Z",
     "shell.execute_reply.started": "2025-12-18T23:07:32.758524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keywords: 4634\n"
     ]
    }
   ],
   "source": [
    "def load_keywords_name_format(path, name2id):\n",
    "    kw2cids = defaultdict(set)\n",
    "    missing = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or \":\" not in line:\n",
    "                continue\n",
    "            cname, rest = line.split(\":\", 1)\n",
    "            cname = cname.strip()\n",
    "            if cname not in name2id:\n",
    "                missing.append(cname)\n",
    "                continue\n",
    "            cid = name2id[cname]\n",
    "            kws = [clean_text(k) for k in rest.split(\",\")]\n",
    "            kws = [k for k in kws if k]\n",
    "            for kw in kws:\n",
    "                kw2cids[kw].add(cid)\n",
    "    if missing:\n",
    "        print(\"WARNING missing class names (showing 10):\", missing[:10])\n",
    "    return kw2cids\n",
    "\n",
    "kw2cids = load_keywords_name_format(KEYWORD_PATH, name2id)\n",
    "print(\"num keywords:\", len(kw2cids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db990c00-17e6-4f14-9515-a6e9c56ba06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:07:43.364913Z",
     "iopub.status.busy": "2025-12-18T23:07:43.364601Z",
     "iopub.status.idle": "2025-12-18T23:07:43.371514Z",
     "shell.execute_reply": "2025-12-18T23:07:43.371027Z",
     "shell.execute_reply.started": "2025-12-18T23:07:43.364891Z"
    }
   },
   "outputs": [],
   "source": [
    "_kw_regex_cache = {}\n",
    "\n",
    "def kw_match(text, kw):\n",
    "    if \" \" in kw:\n",
    "        return kw in text\n",
    "    if kw not in _kw_regex_cache:\n",
    "        _kw_regex_cache[kw] = re.compile(rf\"\\b{re.escape(kw)}\\b\")\n",
    "    return _kw_regex_cache[kw].search(text) is not None\n",
    "\n",
    "def score_doc(text):\n",
    "    scores = defaultdict(float)\n",
    "    for kw, cids in kw2cids.items():\n",
    "        if kw_match(text, kw):\n",
    "            w = 1.0 / (1.0 + np.log(1 + len(cids)))  # generic penalty\n",
    "            for cid in cids:\n",
    "                scores[cid] += w\n",
    "    for cid in list(scores.keys()):\n",
    "        scores[cid] += 0.02 * depths[cid]  # specificity bonus\n",
    "    return scores\n",
    "\n",
    "def predict_labels(text, k_min=2, k_max=3):\n",
    "    scores = score_doc(text)\n",
    "    if not scores:\n",
    "        return []\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    seed_top = [cid for cid, _ in ranked[:k_max]]\n",
    "\n",
    "    cand = set(seed_top)\n",
    "    for cid in seed_top:\n",
    "        cand |= get_ancestors(cid)\n",
    "\n",
    "    cand_ranked = sorted(list(cand), key=lambda c: (scores.get(c, 0.0), depths[c]), reverse=True)\n",
    "\n",
    "    chosen = []\n",
    "    for cid in cand_ranked:\n",
    "        if cid not in chosen:\n",
    "            chosen.append(cid)\n",
    "        if len(chosen) >= k_max:\n",
    "            break\n",
    "\n",
    "    if len(chosen) < k_min:\n",
    "        for cid, _ in ranked:\n",
    "            if cid not in chosen:\n",
    "                chosen.append(cid)\n",
    "            if len(chosen) >= k_min:\n",
    "                break\n",
    "\n",
    "    return chosen[:k_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a5081d-97d8-418f-9c52-d0534271f57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:08:03.031608Z",
     "iopub.status.busy": "2025-12-18T23:08:03.031333Z",
     "iopub.status.idle": "2025-12-18T23:23:22.145762Z",
     "shell.execute_reply": "2025-12-18T23:23:22.145131Z",
     "shell.execute_reply.started": "2025-12-18T23:08:03.031588Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train silver labels: 100%|██████████| 29487/29487 [15:18<00:00, 32.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./artifacts/train_silver_labels.csv\n",
      "Train silver samples: 19500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>omron hem 790it automatic blood pressure monit...</td>\n",
       "      <td>502,493,145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>natural factors whey factors chocolate works w...</td>\n",
       "      <td>355,455,271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>clif bar builder 's bar , 2 . 4 ounce bars i l...</td>\n",
       "      <td>498,8,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>clif bar energy bars these were cheaper than w...</td>\n",
       "      <td>480,449,376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>lumiscope stirrup stockings pair these are ver...</td>\n",
       "      <td>382,199,169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pid                                               text       labels\n",
       "0   0  omron hem 790it automatic blood pressure monit...  502,493,145\n",
       "1   1  natural factors whey factors chocolate works w...  355,455,271\n",
       "2   2  clif bar builder 's bar , 2 . 4 ounce bars i l...    498,8,366\n",
       "3   4  clif bar energy bars these were cheaper than w...  480,449,376\n",
       "4   9  lumiscope stirrup stockings pair these are ver...  382,199,169"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SILVER_PATH = os.path.join(ART_DIR, \"train_silver_labels.csv\")\n",
    "\n",
    "train_rows = []\n",
    "for pid, text in tqdm(pid2text_train.items(), desc=\"Generating train silver labels\"):\n",
    "    labels = predict_labels(text, k_min=MIN_LABELS, k_max=MAX_LABELS)\n",
    "    if not labels:\n",
    "        continue\n",
    "    train_rows.append({\"pid\": pid, \"text\": text, \"labels\": \",\".join(map(str, labels))})\n",
    "\n",
    "train_silver_df = pd.DataFrame(train_rows)\n",
    "train_silver_df.to_csv(TRAIN_SILVER_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", TRAIN_SILVER_PATH)\n",
    "print(\"Train silver samples:\", len(train_silver_df))\n",
    "train_silver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34269c33-21c2-4282-908f-66aaa108d24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:25:40.355301Z",
     "iopub.status.busy": "2025-12-18T23:25:40.355035Z",
     "iopub.status.idle": "2025-12-18T23:25:40.454396Z",
     "shell.execute_reply": "2025-12-18T23:25:40.453841Z",
     "shell.execute_reply.started": "2025-12-18T23:25:40.355282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallback default: [0, 455]\n"
     ]
    }
   ],
   "source": [
    "train_silver_df = pd.read_csv(TRAIN_SILVER_PATH)\n",
    "label_freq = Counter()\n",
    "\n",
    "for s in train_silver_df[\"labels\"]:\n",
    "    for x in str(s).split(\",\"):\n",
    "        label_freq[int(x)] += 1\n",
    "\n",
    "fallback_default = [cid for cid, _ in label_freq.most_common(2)]\n",
    "print(\"Fallback default:\", fallback_default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd631e9-1503-47a1-9282-afbba18f5558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:25:43.096366Z",
     "iopub.status.busy": "2025-12-18T23:25:43.096062Z",
     "iopub.status.idle": "2025-12-18T23:29:57.053335Z",
     "shell.execute_reply": "2025-12-18T23:29:57.052732Z",
     "shell.execute_reply.started": "2025-12-18T23:25:43.096347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 610/610 [02:02<00:00,  4.98it/s]\n",
      "Embedding: 100%|██████████| 615/615 [02:10<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings: (19500, 768) (19658, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"  # general pretrained, not Amazon-finetuned\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "bert.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_texts(texts, batch_size=32, max_length=256):\n",
    "    vecs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        out = bert(**enc).last_hidden_state\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)\n",
    "        pooled = (out * mask).sum(1) / mask.sum(1).clamp(min=1)\n",
    "        vecs.append(pooled.cpu().numpy())\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "train_texts = train_silver_df[\"text\"].astype(str).tolist()\n",
    "test_texts  = [pid2text_test[i] for i in id_list_test]\n",
    "\n",
    "X_train = embed_texts(train_texts, batch_size=32, max_length=256)\n",
    "X_test  = embed_texts(test_texts,  batch_size=32, max_length=256)\n",
    "\n",
    "np.save(os.path.join(ART_DIR, \"train_bert.npy\"), X_train)\n",
    "np.save(os.path.join(ART_DIR, \"test_bert.npy\"),  X_test)\n",
    "json.dump(train_silver_df[\"pid\"].astype(str).tolist(), open(os.path.join(ART_DIR, \"train_ids.json\"), \"w\"))\n",
    "json.dump(id_list_test, open(os.path.join(ART_DIR, \"test_ids.json\"), \"w\"))\n",
    "\n",
    "print(\"Saved embeddings:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef1784c-8fbe-44fe-a960-2cb52392e567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:33:10.847484Z",
     "iopub.status.busy": "2025-12-18T23:33:10.847109Z",
     "iopub.status.idle": "2025-12-18T23:33:11.208886Z",
     "shell.execute_reply": "2025-12-18T23:33:11.208271Z",
     "shell.execute_reply.started": "2025-12-18T23:33:10.847463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 138 val batches: 8\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def labels_str_to_target(labels_str, num_classes=NUM_CLASSES):\n",
    "    y = torch.zeros(num_classes, dtype=torch.float32)\n",
    "    for t in str(labels_str).split(\",\"):\n",
    "        t = t.strip()\n",
    "        if t:\n",
    "            y[int(t)] = 1.0\n",
    "    return y\n",
    "\n",
    "class SilverEmbDataset(Dataset):\n",
    "    def __init__(self, X, label_strs):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.label_strs = list(label_strs)\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\"X\": self.X[i], \"y\": labels_str_to_target(self.label_strs[i])}\n",
    "\n",
    "X_train = np.load(os.path.join(ART_DIR, \"train_bert.npy\"))\n",
    "X_test  = np.load(os.path.join(ART_DIR, \"test_bert.npy\"))\n",
    "\n",
    "label_strs = train_silver_df[\"labels\"].astype(str).tolist()\n",
    "X_tr, X_va, s_tr, s_va = train_test_split(X_train, label_strs, test_size=0.1, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(SilverEmbDataset(X_tr, s_tr), batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(SilverEmbDataset(X_va, s_va), batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"train batches:\", len(train_loader), \"val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e3e04f-a4da-4a45-8dab-0a689cc97afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:33:13.848882Z",
     "iopub.status.busy": "2025-12-18T23:33:13.848567Z",
     "iopub.status.idle": "2025-12-18T23:33:13.860506Z",
     "shell.execute_reply": "2025-12-18T23:33:13.859972Z",
     "shell.execute_reply.started": "2025-12-18T23:33:13.848859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNEnhancedClassifier(\n",
      "  (proj): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (gcn): LabelGCN(\n",
      "    (weights): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 256x256 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 256x256 (cuda:0)]\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LabelGCN(nn.Module):\n",
    "    def __init__(self, emb_dim, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.weights = nn.ParameterList([\n",
    "            nn.Parameter(torch.empty(emb_dim, emb_dim)) for _ in range(num_layers)\n",
    "        ])\n",
    "        for W in self.weights:\n",
    "            nn.init.xavier_uniform_(W)\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, H, A_hat):\n",
    "        for i, W in enumerate(self.weights):\n",
    "            H = A_hat @ H\n",
    "            H = H @ W\n",
    "            if i < self.num_layers - 1:\n",
    "                H = F.relu(H)\n",
    "                H = F.dropout(H, p=self.dropout, training=self.training)\n",
    "        return H\n",
    "\n",
    "class GCNEnhancedClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels, emb_dim=256, num_gcn_layers=2, dropout=0.2, A_hat=None):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(input_dim, emb_dim)\n",
    "        self.label_init_emb = nn.Parameter(torch.empty(num_labels, emb_dim))\n",
    "        nn.init.xavier_uniform_(self.label_init_emb)\n",
    "\n",
    "        self.gcn = LabelGCN(emb_dim=emb_dim, num_layers=num_gcn_layers, dropout=dropout)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.register_buffer(\"A_hat\", A_hat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        label_emb = self.gcn(self.label_init_emb, self.A_hat)   # (C, d)\n",
    "        x_proj = self.proj(x)                                   # (B, d)\n",
    "        x_proj = F.dropout(x_proj, p=self.dropout, training=self.training)\n",
    "        logits = x_proj @ label_emb.t()                         # (B, C)\n",
    "        return logits\n",
    "\n",
    "model = GCNEnhancedClassifier(\n",
    "    input_dim=X_train.shape[1],\n",
    "    num_labels=NUM_CLASSES,\n",
    "    emb_dim=256,\n",
    "    num_gcn_layers=2,\n",
    "    dropout=0.2,\n",
    "    A_hat=A_hat.to(device),\n",
    ").to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0255c8a-dd8b-4791-9550-d5e6076387d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T23:33:58.944232Z",
     "iopub.status.busy": "2025-12-18T23:33:58.943926Z",
     "iopub.status.idle": "2025-12-18T23:34:06.459680Z",
     "shell.execute_reply": "2025-12-18T23:34:06.459123Z",
     "shell.execute_reply.started": "2025-12-18T23:33:58.944213Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 138/138 [00:00<00:00, 262.60it/s]\n",
      "/tmp/ipykernel_18039/99131284.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  probs = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.0200 | val sample-F1: 0.3288\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 138/138 [00:00<00:00, 288.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 0.0197 | val sample-F1: 0.3135\n",
      "  ⏳ no improvement (1/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 138/138 [00:00<00:00, 299.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 0.0196 | val sample-F1: 0.3237\n",
      "  ⏳ no improvement (2/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 138/138 [00:00<00:00, 302.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train loss: 0.0196 | val sample-F1: 0.3303\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 138/138 [00:00<00:00, 304.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train loss: 0.0198 | val sample-F1: 0.3306\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 138/138 [00:00<00:00, 299.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train loss: 0.0195 | val sample-F1: 0.3498\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 138/138 [00:00<00:00, 278.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] train loss: 0.0193 | val sample-F1: 0.3420\n",
      "  ⏳ no improvement (1/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 138/138 [00:00<00:00, 298.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] train loss: 0.0194 | val sample-F1: 0.3486\n",
      "  ⏳ no improvement (2/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 138/138 [00:00<00:00, 304.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] train loss: 0.0194 | val sample-F1: 0.3437\n",
      "  ⏳ no improvement (3/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 138/138 [00:00<00:00, 303.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] train loss: 0.0196 | val sample-F1: 0.3446\n",
      "  ⏳ no improvement (4/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 138/138 [00:00<00:00, 304.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] train loss: 0.0193 | val sample-F1: 0.3404\n",
      "  ⏳ no improvement (5/5)\n",
      "[Early Stopping]\n",
      "Loaded best model. best val sample-F1: 0.34977778792381287\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def sample_f1_score(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    tp = (y_true * y_pred).sum(axis=1)\n",
    "    fp = ((1 - y_true) * y_pred).sum(axis=1)\n",
    "    fn = (y_true * (1 - y_pred)).sum(axis=1)\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn + eps)\n",
    "    return float(np.mean(f1))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sample_f1(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    for batch in loader:\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].cpu().numpy()\n",
    "\n",
    "        logits = model(Xb).cpu().numpy()\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "        yhat = np.zeros_like(probs, dtype=np.float32)\n",
    "        for i in range(probs.shape[0]):\n",
    "            p = probs[i]\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            yhat[i, chosen] = 1.0\n",
    "\n",
    "        all_true.append(yb)\n",
    "        all_pred.append(yhat)\n",
    "\n",
    "    YT = np.vstack(all_true)\n",
    "    YP = np.vstack(all_pred)\n",
    "    return sample_f1_score(YT, YP)\n",
    "\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "\n",
    "THR = 0.35  # try 0.25~0.40 later\n",
    "EPOCHS = 50\n",
    "patience = 5\n",
    "pat = 0\n",
    "best_val = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].to(device)\n",
    "\n",
    "        loss = crit(model(Xb), yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    train_loss = total / len(train_loader)\n",
    "    val_f1 = evaluate_sample_f1(model, val_loader, device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] train loss: {train_loss:.4f} | val sample-F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val:\n",
    "        best_val = val_f1\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        pat = 0\n",
    "        print(\"  ✅ improved\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        print(f\"  ⏳ no improvement ({pat}/{patience})\")\n",
    "        if pat >= patience:\n",
    "            print(\"[Early Stopping]\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best model. best val sample-F1:\", best_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6733762-b9c0-48aa-ab3c-0ba3fa30d4d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T00:02:05.632486Z",
     "iopub.status.busy": "2025-12-19T00:02:05.632004Z",
     "iopub.status.idle": "2025-12-19T00:02:07.331892Z",
     "shell.execute_reply": "2025-12-19T00:02:07.331322Z",
     "shell.execute_reply.started": "2025-12-19T00:02:05.632444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_final_bert_labelgcn.csv rows: 19658\n"
     ]
    }
   ],
   "source": [
    "id_list_test = json.load(open(os.path.join(ART_DIR, \"test_ids.json\")))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(model(torch.tensor(X_test, dtype=torch.float32).to(device))).cpu().numpy()\n",
    "\n",
    "def probs_to_labels_adaptive(p, thr=0.35, min_l=2, max_l=3):\n",
    "    idx = np.argsort(p)[::-1]\n",
    "    chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "    if len(chosen) < min_l:\n",
    "        chosen = idx[:min_l].tolist()\n",
    "    chosen = chosen[:max_l]\n",
    "    return sorted(chosen)\n",
    "\n",
    "pred_labels = [probs_to_labels_adaptive(p, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS) for p in probs]\n",
    "\n",
    "SUBMISSION_PATH = \"submission_final_bert_labelgcn.csv\"\n",
    "with open(SUBMISSION_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])  # competition-required header\n",
    "    for id_, labs in zip(id_list_test, pred_labels):\n",
    "        w.writerow([id_, \",\".join(map(str, labs))])\n",
    "\n",
    "print(\"Saved:\", SUBMISSION_PATH, \"rows:\", len(pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6b7a9e-519c-4d0d-ad1d-58a0b0a0fde2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T00:03:03.554376Z",
     "iopub.status.busy": "2025-12-19T00:03:03.554112Z",
     "iopub.status.idle": "2025-12-19T00:03:07.624390Z",
     "shell.execute_reply": "2025-12-19T00:03:07.623874Z",
     "shell.execute_reply.started": "2025-12-19T00:03:03.554357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 138/138 [00:00<00:00, 306.40it/s]\n",
      "/tmp/ipykernel_18039/3607439042.py:33: RuntimeWarning: overflow encountered in exp\n",
      "  probs = 1 / (1 + np.exp(-logits))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.0198 | val sample-F1: 0.3456\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 138/138 [00:00<00:00, 304.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 0.0193 | val sample-F1: 0.3345\n",
      "  ⏳ no improvement (1/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 138/138 [00:00<00:00, 300.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 0.0192 | val sample-F1: 0.3247\n",
      "  ⏳ no improvement (2/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 138/138 [00:00<00:00, 292.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train loss: 0.0193 | val sample-F1: 0.3453\n",
      "  ⏳ no improvement (3/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 138/138 [00:00<00:00, 296.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train loss: 0.0194 | val sample-F1: 0.3318\n",
      "  ⏳ no improvement (4/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 138/138 [00:00<00:00, 295.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train loss: 0.0194 | val sample-F1: 0.3387\n",
      "  ⏳ no improvement (5/5)\n",
      "[Early Stopping]\n",
      "Loaded best model. best val sample-F1: 0.34564104676246643\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "\n",
    "THR = 0.35      # later we will try 0.25~0.40\n",
    "EPOCHS = 50\n",
    "patience = 5\n",
    "pat = 0\n",
    "best_val = -1.0\n",
    "best_state = None\n",
    "\n",
    "def sample_f1_score(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    tp = (y_true * y_pred).sum(axis=1)\n",
    "    fp = ((1 - y_true) * y_pred).sum(axis=1)\n",
    "    fn = (y_true * (1 - y_pred)).sum(axis=1)\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn + eps)\n",
    "    return float(np.mean(f1))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sample_f1(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].cpu().numpy()\n",
    "\n",
    "        logits = model(Xb).cpu().numpy()\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "        yhat = np.zeros_like(probs, dtype=np.float32)\n",
    "        for i in range(probs.shape[0]):\n",
    "            p = probs[i]\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            yhat[i, chosen] = 1.0\n",
    "\n",
    "        all_true.append(yb)\n",
    "        all_pred.append(yhat)\n",
    "\n",
    "    YT = np.vstack(all_true)\n",
    "    YP = np.vstack(all_pred)\n",
    "    return sample_f1_score(YT, YP)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].to(device)\n",
    "\n",
    "        loss = crit(model(Xb), yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    train_loss = total / len(train_loader)\n",
    "    val_f1 = evaluate_sample_f1(model, val_loader, device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "    print(f\"[Epoch {epoch}] train loss: {train_loss:.4f} | val sample-F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val:\n",
    "        best_val = val_f1\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        pat = 0\n",
    "        print(\"  ✅ improved\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        print(f\"  ⏳ no improvement ({pat}/{patience})\")\n",
    "        if pat >= patience:\n",
    "            print(\"[Early Stopping]\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best model. best val sample-F1:\", best_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "549d3564-40ad-4c60-b6db-c2b604af448c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T00:03:20.008261Z",
     "iopub.status.busy": "2025-12-19T00:03:20.007988Z",
     "iopub.status.idle": "2025-12-19T00:03:21.836659Z",
     "shell.execute_reply": "2025-12-19T00:03:21.835967Z",
     "shell.execute_reply.started": "2025-12-19T00:03:20.008242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_labelgcn.csv rows: 19658\n"
     ]
    }
   ],
   "source": [
    "import csv, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "X_test = np.load(\"artifacts/test_bert.npy\")\n",
    "id_list_test = json.load(open(\"artifacts/test_ids.json\"))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(\n",
    "        model(torch.tensor(X_test, dtype=torch.float32).to(device))\n",
    "    ).cpu().numpy()\n",
    "\n",
    "def probs_to_labels_adaptive(p, thr=0.35, min_l=2, max_l=3):\n",
    "    idx = np.argsort(p)[::-1]\n",
    "    chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "    if len(chosen) < min_l:\n",
    "        chosen = idx[:min_l].tolist()\n",
    "    chosen = chosen[:max_l]\n",
    "    return sorted(chosen)\n",
    "\n",
    "pred_labels = [probs_to_labels_adaptive(p, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS) for p in probs]\n",
    "\n",
    "SUBMISSION_PATH = \"submission_labelgcn.csv\"\n",
    "with open(SUBMISSION_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for id_, labs in zip(id_list_test, pred_labels):\n",
    "        w.writerow([id_, \",\".join(map(str, labs))])\n",
    "\n",
    "print(\"Saved:\", SUBMISSION_PATH, \"rows:\", len(pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCI Environment (Python 3.9)",
   "language": "python",
   "name": "esci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
