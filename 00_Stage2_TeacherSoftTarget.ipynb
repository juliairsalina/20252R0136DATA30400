{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ccf2b56-50d8-48fc-ad1f-e5feb911ef2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:33.436342Z",
     "iopub.status.busy": "2025-12-20T12:05:33.436107Z",
     "iopub.status.idle": "2025-12-20T12:05:34.298328Z",
     "shell.execute_reply": "2025-12-20T12:05:34.297451Z",
     "shell.execute_reply.started": "2025-12-20T12:05:33.436321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/envs/esci/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (4.60.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/esci/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/esci/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/esci/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d611e12f-113f-4231-8a5d-75a82d29c66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:34.299688Z",
     "iopub.status.busy": "2025-12-20T12:05:34.299486Z",
     "iopub.status.idle": "2025-12-20T12:05:34.302948Z",
     "shell.execute_reply": "2025-12-20T12:05:34.302407Z",
     "shell.execute_reply.started": "2025-12-20T12:05:34.299668Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Also ensure these are present for the training loop\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "91d96782-2059-427f-8ead-4ad5e696d223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:34.303605Z",
     "iopub.status.busy": "2025-12-20T12:05:34.303451Z",
     "iopub.status.idle": "2025-12-20T12:05:34.310359Z",
     "shell.execute_reply": "2025-12-20T12:05:34.309627Z",
     "shell.execute_reply.started": "2025-12-20T12:05:34.303589Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================================\n",
    "# 1. SETUP & MODEL DEFINITION\n",
    "# ==========================================================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLASSES = 531\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b0438f3-a80a-4b4b-8e6a-3736be8957a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:34.415029Z",
     "iopub.status.busy": "2025-12-20T12:05:34.414771Z",
     "iopub.status.idle": "2025-12-20T12:05:34.425290Z",
     "shell.execute_reply": "2025-12-20T12:05:34.424611Z",
     "shell.execute_reply.started": "2025-12-20T12:05:34.415013Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 2. ARCHITECTURE: Multi-Head GATv2 + Path Attention\n",
    "# ==========================================================\n",
    "class MultiHeadPathLabelAttn(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, dropout=0.2): # Increased to 8 heads for Strategy B\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(dim, dim, bias=False)\n",
    "        self.w_k = nn.Linear(dim, dim, bias=False)\n",
    "        self.v_attn = nn.Linear(self.head_dim, 1, bias=False)\n",
    "        self.v_proj = nn.Linear(dim, dim, bias=False)\n",
    "        \n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Learnable gate to balance self-information vs. hierarchy information\n",
    "        self.gate = nn.Parameter(torch.ones(1) * 0.5)\n",
    "\n",
    "    def forward(self, E, ancestors):\n",
    "        L, d = E.shape\n",
    "        Q = self.w_q(E).view(L, self.num_heads, self.head_dim)\n",
    "        K = self.w_k(E).view(L, self.num_heads, self.head_dim)\n",
    "        V = self.v_proj(E).view(L, self.num_heads, self.head_dim)\n",
    "        \n",
    "        out = torch.zeros_like(E)\n",
    "        for c in range(L):\n",
    "            anc = ancestors[c]\n",
    "            if not anc:\n",
    "                out[c] = E[c]\n",
    "                continue\n",
    "            \n",
    "            # GATv2 Dynamic Attention\n",
    "            q_c = Q[c:c+1] \n",
    "            k_a = K[anc]\n",
    "            \n",
    "            # Compute scores: LeakyReLU(Q + K) is more expressive than standard GAT\n",
    "            scores = self.v_attn(F.leaky_relu(q_c + k_a, 0.2)).squeeze(-1)\n",
    "            attn = F.softmax(scores, dim=0) \n",
    "            \n",
    "            # Aggregate hierarchy message\n",
    "            msg = (attn.unsqueeze(-1) * V[anc]).sum(dim=0).view(d)\n",
    "            \n",
    "            # Apply Gating\n",
    "            out[c] = (self.gate * E[c]) + ((1.0 - self.gate) * msg)\n",
    "            \n",
    "        # Strategy B: Added Residual Connection (out + E) before LayerNorm\n",
    "        # This ensures specific label meanings aren't \"washed out\" by broad parent info\n",
    "        return self.ln(self.dropout(out) + E)\n",
    "\n",
    "class ProposedClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels, emb_dim, E_label_768, ancestors):\n",
    "        super().__init__()\n",
    "        self.doc_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, emb_dim), \n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.label_proj = nn.Linear(768, emb_dim, bias=False)\n",
    "        self.register_buffer(\"E_text\", E_label_768.float())\n",
    "        \n",
    "        # Consistent num_heads with the Attention class\n",
    "        self.label_attn = MultiHeadPathLabelAttn(emb_dim, num_heads=8)\n",
    "        self.ancestors = ancestors\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 1. Project product BERT features\n",
    "        h = self.doc_proj(X)\n",
    "        \n",
    "        # 2. Refine label embeddings using hierarchy attention\n",
    "        # Label proj maps BERT label space (768) to joint emb_dim (256)\n",
    "        E = self.label_attn(self.label_proj(self.E_text), self.ancestors)\n",
    "        \n",
    "        # 3. Compute compatibility (Dot Product)\n",
    "        return h @ E.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b00bbda-d3ab-4af9-8dcf-49cef3bfbb1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:34.988788Z",
     "iopub.status.busy": "2025-12-20T12:05:34.988515Z",
     "iopub.status.idle": "2025-12-20T12:05:35.123415Z",
     "shell.execute_reply": "2025-12-20T12:05:35.122782Z",
     "shell.execute_reply.started": "2025-12-20T12:05:34.988764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProposedClassifier(\n",
       "  (doc_proj): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (label_proj): Linear(in_features=768, out_features=256, bias=False)\n",
       "  (label_attn): MultiHeadPathLabelAttn(\n",
       "    (w_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (w_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (v_attn): Linear(in_features=32, out_features=1, bias=False)\n",
       "    (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2. LOAD DATA & TEACHER MODEL (.pth)\n",
    "# ==========================================================\n",
    "data = torch.load(\"preprocessed_features.pth\", weights_only=False)\n",
    "X_train, Y_silver = data[\"X_train\"], data[\"y_all\"]\n",
    "E_label_768, ancestors = data[\"E_label_768\"], data[\"ancestors\"]\n",
    "X_test, test_ids = data[\"X_test\"], data[\"test_ids\"]\n",
    "\n",
    "if isinstance(E_label_768, np.ndarray): E_label_768 = torch.from_numpy(E_label_768)\n",
    "\n",
    "# Load Teacher\n",
    "teacher = ProposedClassifier(768, NUM_CLASSES, 256, E_label_768, ancestors).to(device)\n",
    "teacher.load_state_dict(torch.load(\"stage1_teacher_model1.pth\"))\n",
    "teacher.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e37d38fc-c158-4156-bdff-45fe52fdc747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:36.120297Z",
     "iopub.status.busy": "2025-12-20T12:05:36.120103Z",
     "iopub.status.idle": "2025-12-20T12:05:36.264537Z",
     "shell.execute_reply": "2025-12-20T12:05:36.263854Z",
     "shell.execute_reply.started": "2025-12-20T12:05:36.120280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test_ids loaded from .pth file.\n",
      "Teacher model loaded and set to eval mode.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2. LOAD DATA & TEACHER MODEL (.pth)\n",
    "# ==========================================================\n",
    "import os\n",
    "\n",
    "# Load with weights_only=False to allow list/numpy recovery\n",
    "data = torch.load(\"preprocessed_features.pth\", weights_only=False)\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "Y_silver = data[\"y_all\"]\n",
    "E_label_768 = data[\"E_label_768\"]\n",
    "ancestors = data[\"ancestors\"]\n",
    "X_test = data[\"X_test\"]\n",
    "\n",
    "# --- SMART ID RECOVERY ---\n",
    "try:\n",
    "    test_ids = data[\"test_ids\"]\n",
    "    print(\" test_ids loaded from .pth file.\")\n",
    "except KeyError:\n",
    "    print(\"test_ids not found in .pth. Recovering from raw text file...\")\n",
    "    test_ids = []\n",
    "    # Adjust this path to where your test_corpus.txt is located\n",
    "    with open(\"./Amazon_products/test/test_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                test_ids.append(parts[0])\n",
    "    print(f\" Recovered {len(test_ids)} IDs from corpus.\")\n",
    "\n",
    "if isinstance(E_label_768, np.ndarray): \n",
    "    E_label_768 = torch.from_numpy(E_label_768)\n",
    "\n",
    "# --- LOAD TEACHER ---\n",
    "teacher = ProposedClassifier(768, NUM_CLASSES, 256, E_label_768, ancestors).to(device)\n",
    "teacher.load_state_dict(torch.load(\"stage1_teacher_model1.pth\"))\n",
    "teacher.eval()\n",
    "print(\"Teacher model loaded and set to eval mode.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f701c186-5e6c-4407-9544-84765156f30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:05:37.139878Z",
     "iopub.status.busy": "2025-12-20T12:05:37.139616Z",
     "iopub.status.idle": "2025-12-20T12:05:52.834206Z",
     "shell.execute_reply": "2025-12-20T12:05:52.833549Z",
     "shell.execute_reply.started": "2025-12-20T12:05:37.139857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Q_soft targets using Teacher model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Distilling Knowledge: 100%|██████████| 116/116 [00:15<00:00,  7.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# GENERATE SOFT TARGETS (Run this before the training loop)\n",
    "# ==========================================================\n",
    "LAMBDA, TEMP = 0.7, 2.5 \n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_q_soft(model, X, Y_hard, temp=2.5, lam=0.7):\n",
    "    model.eval()\n",
    "    Q_list = []\n",
    "    # Process in batches to prevent GPU Out-of-Memory (OOM)\n",
    "    for i in tqdm(range(0, len(X), 256), desc=\"Distilling Knowledge\"):\n",
    "        bx = X[i:i+256].to(device)\n",
    "        # Apply temperature scaling to soften the distribution\n",
    "        P_teacher = torch.sigmoid(model(bx) / temp)\n",
    "        by = Y_hard[i:i+256].to(device)\n",
    "        # Mix teacher opinion with silver labels\n",
    "        Q_list.append(((1.0 - lam) * by + lam * P_teacher).cpu())\n",
    "    return torch.cat(Q_list, dim=0)\n",
    "\n",
    "print(\"Generating Q_soft targets using Teacher model...\")\n",
    "Q_soft = generate_q_soft(teacher, X_train, Y_silver, temp=TEMP, lam=LAMBDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9816a93a-f3f7-47e5-a336-13ade0341e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:07:22.976369Z",
     "iopub.status.busy": "2025-12-20T12:07:22.976076Z",
     "iopub.status.idle": "2025-12-20T12:07:22.984616Z",
     "shell.execute_reply": "2025-12-20T12:07:22.984043Z",
     "shell.execute_reply.started": "2025-12-20T12:07:22.976350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " val_loader defined. Ready to evaluate on 4424 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Recreate the indices split (MUST use same random_state=42 as Stage 1)\n",
    "all_indices = np.arange(len(X_train))\n",
    "train_idx, val_idx = train_test_split(all_indices, test_size=0.15, random_state=42)\n",
    "\n",
    "# 2. Define the Dataset Class (if not already in memory)\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return {\"X\": self.X[i], \"y\": self.y[i]}\n",
    "\n",
    "# 3. Create the val_loader\n",
    "# Note: We use the original Silver Y_all here to check against \"Ground Truth\"\n",
    "val_ds = MultiLabelDataset(X_train[val_idx], Y_silver[val_idx])\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "# 4. Define train_indices for your loop\n",
    "train_indices = train_idx \n",
    "\n",
    "print(f\" val_loader defined. Ready to evaluate on {len(val_idx)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a41552a-60d9-4bc4-80e6-96479a804fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:07:26.294620Z",
     "iopub.status.busy": "2025-12-20T12:07:26.294349Z",
     "iopub.status.idle": "2025-12-20T12:07:26.299486Z",
     "shell.execute_reply": "2025-12-20T12:07:26.298958Z",
     "shell.execute_reply.started": "2025-12-20T12:07:26.294601Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_f1(model, loader, thr=0.35):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            Xb, yb = batch[\"X\"].to(device), batch[\"y\"].to(device)\n",
    "            probs = torch.sigmoid(model(Xb)).cpu().numpy()\n",
    "            for p in probs:\n",
    "                idx = np.argsort(p)[::-1]\n",
    "                chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "                if len(chosen) < 2: chosen = idx[:2].tolist()\n",
    "                vec = np.zeros(NUM_CLASSES)\n",
    "                vec[chosen[:3]] = 1\n",
    "                all_preds.append(vec)\n",
    "            all_targets.append(yb.cpu().numpy())\n",
    "    return f1_score(np.vstack(all_targets), np.vstack(all_preds), average='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e059c2-4d8a-4fc0-bb97-7722f9beef69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:07:28.101074Z",
     "iopub.status.busy": "2025-12-20T12:07:28.100808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 1: 100%|██████████| 392/392 [03:00<00:00,  2.17it/s, loss=0.0403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1931\n",
      "   ⭐ New Best Student! Saved with F1: 0.1931\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 2: 100%|██████████| 392/392 [03:06<00:00,  2.11it/s, loss=0.0402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1942\n",
      "   ⭐ New Best Student! Saved with F1: 0.1942\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 3: 100%|██████████| 392/392 [03:02<00:00,  2.15it/s, loss=0.0403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1982\n",
      "   ⭐ New Best Student! Saved with F1: 0.1982\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 4: 100%|██████████| 392/392 [03:06<00:00,  2.10it/s, loss=0.0405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1876\n",
      "   No improvement for 1 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 5: 100%|██████████| 392/392 [03:14<00:00,  2.02it/s, loss=0.0403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1937\n",
      "   No improvement for 2 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 6: 100%|██████████| 392/392 [03:23<00:00,  1.93it/s, loss=0.0405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1921\n",
      "   No improvement for 3 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 7: 100%|██████████| 392/392 [03:12<00:00,  2.04it/s, loss=0.0402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1976\n",
      "   No improvement for 4 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 8: 100%|██████████| 392/392 [02:57<00:00,  2.21it/s, loss=0.0407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1880\n",
      "   No improvement for 5 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 9: 100%|██████████| 392/392 [02:57<00:00,  2.21it/s, loss=0.0402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1928\n",
      "   No improvement for 6 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 10: 100%|██████████| 392/392 [06:46<00:00,  1.04s/it, loss=0.0403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1924\n",
      "   No improvement for 7 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 11: 100%|██████████| 392/392 [02:58<00:00,  2.20it/s, loss=0.0406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 Results:\n",
      "   Train Loss: 0.0397 | Val Sample-F1: 0.1894\n",
      "   No improvement for 8 epochs.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Student Epoch 12:  53%|█████▎    | 209/392 [01:34<01:26,  2.13it/s, loss=0.0380]"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 4. CONFIDENCE-AWARE STUDENT TRAINING (EARLY STOPPING)\n",
    "# ==========================================================\n",
    "best_student_f1 = 0.0\n",
    "patience = 7\n",
    "epochs_no_improve = 0\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    student.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    pbar = tqdm(range(0, len(train_indices), 64), desc=f\"Student Epoch {epoch}\")\n",
    "    for i in pbar:\n",
    "        idx = train_indices[i:i+64]\n",
    "        bx, bq = X_train[idx].to(device), Q_soft[idx].to(device)\n",
    "        \n",
    "        preds = torch.sigmoid(student(bx))\n",
    "        w = get_conf_weight(bq) \n",
    "        \n",
    "        loss = (F.binary_cross_entropy(preds, bq, reduction='none') * w).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(student.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    # --- EVALUATION STEP ---\n",
    "    val_f1 = evaluate_f1(student, val_loader) \n",
    "    avg_train_loss = total_train_loss / (max(1, len(train_indices) // 64))\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch} Results:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f} | Val Sample-F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Early Stopping & Model Saving Logic\n",
    "    if val_f1 > best_student_f1:\n",
    "        best_student_f1 = val_f1\n",
    "        epochs_no_improve = 0  # Reset counter\n",
    "        torch.save(student.state_dict(), \"final_student_model.pth\")\n",
    "        print(f\"   ⭐ New Best Student! Saved with F1: {val_f1:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"   No improvement for {epochs_no_improve} epochs.\")\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Trigger Early Stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch}! Best Val F1: {best_student_f1:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "170c5628-c1a1-4e27-9496-fd0e3f2c1401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T09:06:56.642154Z",
     "iopub.status.busy": "2025-12-20T09:06:56.641984Z",
     "iopub.status.idle": "2025-12-20T09:07:08.520177Z",
     "shell.execute_reply": "2025-12-20T09:07:08.519131Z",
     "shell.execute_reply.started": "2025-12-20T09:06:56.642137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Final Inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Batches: 100%|██████████| 77/77 [00:10<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission file...\n",
      "Done! File saved as: 2023320344_Final.csv\n",
      "  id   label\n",
      "0  0  10,206\n",
      "1  1  10,200\n",
      "2  2   10,11\n",
      "3  3   0,206\n",
      "4  4   10,11\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 5. FINAL INFERENCE & KAGGLE SUBMISSION\n",
    "# ==========================================================\n",
    "student.eval()\n",
    "all_probs = []\n",
    "\n",
    "# Use .detach().clone() to resolve the UserWarning\n",
    "# We also move it to CPU first if it's large, then batch it to the GPU\n",
    "Xt_tensor = X_test.detach().clone().to(torch.float32)\n",
    "\n",
    "print(\"Starting Final Inference...\")\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(Xt_tensor), 256), desc=\"Inference Batches\"):\n",
    "        batch_x = Xt_tensor[i : i+256].to(device)\n",
    "        logits = student(batch_x)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "\n",
    "# Stack all probabilities [N_test, 531]\n",
    "probs = np.vstack(all_probs)\n",
    "\n",
    "def get_labels(p, thr=0.35):\n",
    "    \"\"\"\n",
    "    Selects top labels based on threshold and forces count \n",
    "    between 2 and 3 to optimize Sample-F1.\n",
    "    \"\"\"\n",
    "    idx = np.argsort(p)[::-1]\n",
    "    # Pick labels passing the threshold\n",
    "    chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "    \n",
    "    # Competition Constraint: Force at least 2\n",
    "    if len(chosen) < 2:\n",
    "        chosen = idx[:2].tolist()\n",
    "    \n",
    "    # Competition Constraint: Force at most 3\n",
    "    # Keeping it to 3 prevents 'over-predicting' which hurts F1\n",
    "    final_selection = sorted(chosen[:3])\n",
    "    \n",
    "    return \",\".join(map(str, final_selection))\n",
    "\n",
    "# Generate the submission dataframe\n",
    "print(\"Creating submission file...\")\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids, \n",
    "    \"label\": [get_labels(p) for p in probs]\n",
    "})\n",
    "\n",
    "# Save with your specific filename\n",
    "submission.to_csv(\"2023320344_Final.csv\", index=False)\n",
    "print(\"Done! File saved as: 2023320344_Final.csv\")\n",
    "\n",
    "# Quick preview\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4439d1-9284-450b-9ab4-4c697ccaa5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embedding_clusters(features, labels, title=\"Embedding Space\"):\n",
    "    # 1. PCA: Reduce to 50 dimensions to preserve global structure \n",
    "    pca = PCA(n_components=50)\n",
    "    X_pca = pca.fit_transform(features[:2000].cpu().numpy()) # Sample 2000 for speed\n",
    "    \n",
    "    # 2. t-SNE: Project to 2D for human viewing \n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    X_tsne = tsne.fit_transform(X_pca)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # We color by the most frequent label in the sample for visual clarity\n",
    "    colors = np.argmax(labels[:2000].cpu().numpy(), axis=1)\n",
    "    \n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=colors, cmap='jet', alpha=0.6, s=15)\n",
    "    plt.colorbar(label='Category ID')\n",
    "    plt.title(f\"PCA-initialized t-SNE: {title}\")\n",
    "    plt.savefig(f\"{title}_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "# Use it like this:\n",
    "plot_embedding_clusters(X_train, Y_silver, \"Raw BERT Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0a77f-c5dd-43ea-92b9-674ec113154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Raw State (The BERT embeddings before any training)\n",
    "plot_embedding_clusters(X_train, Y_silver, \"1_Raw_BERT_Features\")\n",
    "\n",
    "# B. Teacher State (Embeddings after Stage 1)\n",
    "# We need to extract the hidden 'h' from the teacher model\n",
    "teacher.eval()\n",
    "with torch.no_grad():\n",
    "    h_teacher = teacher.doc_proj(X_train[:2000].to(device))\n",
    "plot_embedding_clusters(h_teacher, Y_silver, \"2_Teacher_Refined_Features\")\n",
    "\n",
    "# C. Final Student State (Embeddings after Stage 2 Refinement)\n",
    "student.eval()\n",
    "with torch.no_grad():\n",
    "    h_student = student.doc_proj(X_train[:2000].to(device))\n",
    "plot_embedding_clusters(h_student, Y_silver, \"3_Final_Student_Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f6859-3666-45eb-bc6b-f8dfa9dd48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_analysis(features, labels, title, n_samples=5000):\n",
    "    # Ensure we don't exceed actual data length\n",
    "    n = min(n_samples, len(features))\n",
    "    \n",
    "    # PCA is fast, t-SNE is slow. \n",
    "    # PCA helps 'denoise' high-dimensional BERT data before t-SNE tries to map it.\n",
    "    pca = PCA(n_components=50)\n",
    "    feat_subset = features[:n].cpu().numpy() if torch.is_tensor(features) else features[:n]\n",
    "    X_pca = pca.fit_transform(feat_subset)\n",
    "    \n",
    "    print(f\"Running t-SNE on {n} samples...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=50, random_state=42, init='pca')\n",
    "    X_tsne = tsne.fit_transform(X_pca)\n",
    "\n",
    "plot_full_analysis(X_train, Y_silver, \"1_Raw_BERT_Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da5753-9da3-45d6-b461-71e1c6d1092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the root and data directories\n",
    "PROJECT_ROOT = \".\"\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"Amazon_products\")\n",
    "\n",
    "# Define the specific hierarchy path\n",
    "HIER_PATH = os.path.join(DATA_DIR, \"class_hierarchy.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c7fc2-e8a1-4546-98a7-737f7acf970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 1. Re-define the loading function\n",
    "def load_hierarchy(path):\n",
    "    parents = defaultdict(set)  # child -> set of parents\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            p_str, c_str = line.split(\"\\t\")\n",
    "            p, c = int(p_str), int(c_str)\n",
    "            parents[c].add(p)\n",
    "    return parents\n",
    "\n",
    "# 2. Load the file (Ensure HIER_PATH is defined)\n",
    "HIER_PATH = os.path.join(DATA_DIR, \"class_hierarchy.txt\")\n",
    "parents = load_hierarchy(HIER_PATH)\n",
    "\n",
    "print(f\"Hierarchy loaded with {len(parents)} child-parent relations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b901aa-120f-4014-80d0-2dce00681af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hvr(pred_labels, parents_dict):\n",
    "    \"\"\"\n",
    "    Calculates the Hierarchy Violation Rate.\n",
    "    A violation occurs if a child label is predicted but NONE of its parents are.\n",
    "    \"\"\"\n",
    "    total_child_preds = 0\n",
    "    violations = 0\n",
    "\n",
    "    for labs in pred_labels:\n",
    "        # labs is a list of predicted label indices for one sample\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents_dict.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue  # Root nodes have no parent constraints\n",
    "            \n",
    "            total_child_preds += 1\n",
    "            # Check if at least one parent is in the predicted set\n",
    "            if len(S.intersection(ps)) == 0:\n",
    "                violations += 1\n",
    "\n",
    "    hvr = violations / max(total_child_preds, 1)\n",
    "    return hvr, violations, total_child_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae96057-c79d-4892-b620-d4441169497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_stage2_with_hvr(model, loader, parents_dict, thr=0.20):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        probs = torch.sigmoid(model(Xb)).cpu().numpy()\n",
    "        \n",
    "        # Convert probabilities to discrete labels for HVR check\n",
    "        for p in probs:\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            # Select labels based on threshold (Strategy A)\n",
    "            chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "            # Enforce competition constraints (2nd-3rd best if none pass)\n",
    "            if len(chosen) < 2: chosen = idx[:2].tolist()\n",
    "            all_preds.append(chosen[:3]) # Top 3 labels\n",
    "\n",
    "    # Calculate HRV\n",
    "    hvr_rate, v_cnt, total_c = check_hvr(all_preds, parents_dict)\n",
    "    return hvr_rate, v_cnt, total_c\n",
    "\n",
    "# --- Inside your Stage 2 Training Loop ---\n",
    "hvr_rate, v_cnt, total_c = evaluate_stage2_with_hvr(student, val_loader, parents)\n",
    "print(f\"   HRV Rate: {hvr_rate:.4f} ({v_cnt} violations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741fd915-1685-422c-8fe7-dbfd8a8767c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now 'parents' is defined in your session\n",
    "hvr_rate, v_cnt, total_c = evaluate_stage2_with_hvr(student, val_loader, parents)\n",
    "print(f\"Stage 2 Hierarchical Health:\")\n",
    "print(f\"HRV Rate: {hvr_rate:.4f} ({v_cnt} violations in {total_c} predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dd36b-c4e2-44a2-989a-aa6e9f2d14fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCI Environment (Python 3.9)",
   "language": "python",
   "name": "esci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
