{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78bfbd7-2212-4de1-bf58-cf73adee4593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:26:03.639631Z",
     "iopub.status.busy": "2025-12-20T02:26:03.639063Z",
     "iopub.status.idle": "2025-12-20T02:26:03.645010Z",
     "shell.execute_reply": "2025-12-20T02:26:03.644312Z",
     "shell.execute_reply.started": "2025-12-20T02:26:03.639607Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 1: Imports, Seeds, and Paths\n",
    "# ==========================================================\n",
    "import os, re, json, random\n",
    "from collections import defaultdict, deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATA_DIR = \"./Amazon_products\"\n",
    "NUM_CLASSES = 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2d1ebe-e854-4223-868c-ea71bc8adf45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:26:06.692609Z",
     "iopub.status.busy": "2025-12-20T02:26:06.692290Z",
     "iopub.status.idle": "2025-12-20T02:26:07.562793Z",
     "shell.execute_reply": "2025-12-20T02:26:07.561809Z",
     "shell.execute_reply.started": "2025-12-20T02:26:06.692585Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 2: Text Cleaning & Corpus Loading\n",
    "# ==========================================================\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s or \"\"\n",
    "    s = TAG_RE.sub(\" \", s).lower()\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def load_corpus(path):\n",
    "    pids, texts = [], []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                pids.append(parts[0])\n",
    "                texts.append(clean_text(parts[1]))\n",
    "    return pids, texts\n",
    "\n",
    "train_ids, train_texts = load_corpus(os.path.join(DATA_DIR, \"train\", \"train_corpus.txt\"))\n",
    "test_ids, test_texts = load_corpus(os.path.join(DATA_DIR, \"test\", \"test_corpus.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0b1a86-284a-4308-b829-6fe2df62aba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:26:21.715672Z",
     "iopub.status.busy": "2025-12-20T02:26:21.715371Z",
     "iopub.status.idle": "2025-12-20T02:26:21.723786Z",
     "shell.execute_reply": "2025-12-20T02:26:21.723182Z",
     "shell.execute_reply.started": "2025-12-20T02:26:21.715650Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 3: Hierarchy & Ancestor Path Building\n",
    "# ==========================================================\n",
    "# Build parent mapping\n",
    "parents = defaultdict(set)\n",
    "with open(os.path.join(DATA_DIR, \"class_hierarchy.txt\"), \"r\") as f:\n",
    "    for line in f:\n",
    "        p, c = map(int, line.strip().split(\"\\t\"))\n",
    "        parents[c].add(p)\n",
    "\n",
    "def build_ancestor_list(parents_dict, num_classes, max_anc=8):\n",
    "    \"\"\"Climbs the hierarchy to create paths for the GAT+Path model\"\"\"\n",
    "    ancestors = []\n",
    "    for c in range(num_classes):\n",
    "        seen, q, anc = set(), deque(list(parents_dict.get(c, set()))), []\n",
    "        while q and len(anc) < max_anc:\n",
    "            p = q.popleft()\n",
    "            if p not in seen:\n",
    "                seen.add(p); anc.append(p)\n",
    "                for pp in parents_dict.get(p, set()):\n",
    "                    if pp not in seen: q.append(pp)\n",
    "        ancestors.append(anc)\n",
    "    return ancestors\n",
    "\n",
    "ancestor_list = build_ancestor_list(parents, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86b19508-964f-4269-872a-624a750d6f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:40:38.166223Z",
     "iopub.status.busy": "2025-12-20T02:40:38.165914Z",
     "iopub.status.idle": "2025-12-20T02:40:38.171107Z",
     "shell.execute_reply": "2025-12-20T02:40:38.170613Z",
     "shell.execute_reply.started": "2025-12-20T02:40:38.166204Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 4: Build Keyword Mapping\n",
    "# ==========================================================\n",
    "# Load the class names to create keywords for matching\n",
    "id2name = {}\n",
    "with open(os.path.join(DATA_DIR, \"classes.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        m = re.match(r\"^(\\d+)\\s+(.+)$\", line.strip())\n",
    "        if m: id2name[int(m.group(1))] = m.group(2)\n",
    "\n",
    "# Create a mapping of keyword -> list of category IDs\n",
    "kw2cids = defaultdict(list)\n",
    "for cid, name in id2name.items():\n",
    "    # Clean the category name to use as a keyword\n",
    "    kw = name.lower().strip()\n",
    "    kw2cids[kw].append(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b37ea87-6599-42e8-80d5-df7a89fc7bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:40:40.062116Z",
     "iopub.status.busy": "2025-12-20T02:40:40.061737Z",
     "iopub.status.idle": "2025-12-20T02:40:44.027868Z",
     "shell.execute_reply": "2025-12-20T02:40:44.027331Z",
     "shell.execute_reply.started": "2025-12-20T02:40:40.062098Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Silver Labeling: 100%|██████████| 29487/29487 [00:03<00:00, 7447.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 4a: Silver Labeling (Core Class Generation)\n",
    "# ==========================================================\n",
    "# 1. Load keywords (Assumes kw2cids is built from classes.txt)\n",
    "# 2. Perform match to create y_core (Original Keyword matches)\n",
    "# 3. Expand y_core to y_all (Keyword matches + All Ancestors)\n",
    "\n",
    "# ==========================================================\n",
    "# Cell 5: Generate Silver Labels (Core + Expanded)\n",
    "# ==========================================================\n",
    "def generate_silver_labels(texts, kw2cids, parents, num_classes):\n",
    "    y_core = np.zeros((len(texts), num_classes), dtype=np.float32)\n",
    "    y_all = np.zeros((len(texts), num_classes), dtype=np.float32)\n",
    "    \n",
    "    for i, text in enumerate(tqdm(texts, desc=\"Silver Labeling\")):\n",
    "        matched_cids = set()\n",
    "        # Check each keyword against the product text\n",
    "        for kw, cids in kw2cids.items():\n",
    "            if kw in text:\n",
    "                matched_cids.update(cids)\n",
    "        \n",
    "        for cid in matched_cids:\n",
    "            # y_core: The specific category found via keywords\n",
    "            y_core[i, cid] = 1.0\n",
    "            \n",
    "            # y_all: The category + all its ancestors (Hierarchy Expansion)\n",
    "            stack = [cid]\n",
    "            while stack:\n",
    "                curr = stack.pop()\n",
    "                y_all[i, curr] = 1.0\n",
    "                for p in parents.get(curr, []):\n",
    "                    stack.append(p)\n",
    "                    \n",
    "    return y_core, y_all\n",
    "\n",
    "# CRITICAL STEP: Call the function to define the variables\n",
    "y_core, y_all = generate_silver_labels(train_texts, kw2cids, parents, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3e3a7c-5f84-4e05-951e-1b83d63b179d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:41:07.071372Z",
     "iopub.status.busy": "2025-12-20T02:41:07.071009Z",
     "iopub.status.idle": "2025-12-20T02:46:47.173803Z",
     "shell.execute_reply": "2025-12-20T02:46:47.173125Z",
     "shell.execute_reply.started": "2025-12-20T02:41:07.071345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT Encoding: 100%|██████████| 922/922 [03:18<00:00,  4.65it/s]\n",
      "BERT Encoding: 100%|██████████| 615/615 [02:21<00:00,  4.36it/s]\n",
      "BERT Encoding: 100%|██████████| 17/17 [00:00<00:00, 93.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Cell 5: BERT Feature Extraction\n",
    "# ==========================================================\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# We load the model and move it to GPU, then set to .eval() to disable dropout\n",
    "bert_model = AutoModel.from_pretrained(MODEL_NAME).to(device).eval()\n",
    "\n",
    "@torch.no_grad() # Disable gradient calculation to save memory/time\n",
    "def get_bert_features(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"BERT Encoding\"):\n",
    "        batch = texts[i : i+batch_size]\n",
    "        # Tokenize and move to GPU\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, max_length=256, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # Get hidden states\n",
    "        outputs = bert_model(**inputs)\n",
    "        \n",
    "        # MEAN POOLING: Instead of just taking the [CLS] token, we average \n",
    "        # all token embeddings for a more stable representation of the description.\n",
    "        last_hidden_state = outputs.last_hidden_state # [batch, seq_len, 768]\n",
    "        mask = inputs[\"attention_mask\"].unsqueeze(-1) # [batch, seq_len, 1]\n",
    "        \n",
    "        # Sum embeddings and divide by the number of non-padding tokens\n",
    "        sum_embeddings = torch.sum(last_hidden_state * mask, 1)\n",
    "        count_embeddings = torch.clamp(mask.sum(1), min=1e-9)\n",
    "        mean_pooled = sum_embeddings / count_embeddings\n",
    "        \n",
    "        all_embeddings.append(mean_pooled.cpu().numpy())\n",
    "        \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "# Execute for Train and Test\n",
    "X_train = get_bert_features(train_texts)\n",
    "X_test = get_bert_features(test_texts)\n",
    "\n",
    "# Generate Label Embeddings (Used by the Attention layer)\n",
    "class_names = [id2name.get(i, f\"Category {i}\") for i in range(NUM_CLASSES)]\n",
    "E_label_768 = get_bert_features(class_names) # [531, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd7ae82-a234-4a92-bc32-f74044be7feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T02:48:51.708304Z",
     "iopub.status.busy": "2025-12-20T02:48:51.708068Z",
     "iopub.status.idle": "2025-12-20T02:48:51.913273Z",
     "shell.execute_reply": "2025-12-20T02:48:51.912551Z",
     "shell.execute_reply.started": "2025-12-20T02:48:51.708286Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Cell 6: Save Preprocessed Data\n",
    "# ==========================================================\n",
    "# Saving as .pth for fast loading in the training notebook\n",
    "torch.save({\n",
    "    \"X_train\": torch.tensor(X_train, dtype=torch.float32),\n",
    "    \"X_test\": torch.tensor(X_test, dtype=torch.float32),\n",
    "    \"y_core\": torch.tensor(y_core, dtype=torch.float32),\n",
    "    \"y_all\": torch.tensor(y_all, dtype=torch.float32),\n",
    "    \"E_label_768\": E_label_768,\n",
    "    \"ancestors\": ancestor_list\n",
    "}, \"preprocessed_features.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCI Environment (Python 3.9)",
   "language": "python",
   "name": "esci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
