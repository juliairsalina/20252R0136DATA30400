{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab995bc5-a89d-4b3c-bdc4-432e3c999ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:07.480647Z",
     "iopub.status.busy": "2025-12-19T13:04:07.480387Z",
     "iopub.status.idle": "2025-12-19T13:04:07.487677Z",
     "shell.execute_reply": "2025-12-19T13:04:07.487074Z",
     "shell.execute_reply.started": "2025-12-19T13:04:07.480626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 1: Imports + paths + reproducibility (required)\n",
    "# =========================\n",
    "\n",
    "import os, re, csv, json, random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "PROJECT_ROOT = \".\"\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"Amazon_products\")\n",
    "\n",
    "TRAIN_CORPUS_PATH = os.path.join(DATA_DIR, \"train\", \"train_corpus.txt\")\n",
    "TEST_CORPUS_PATH  = os.path.join(DATA_DIR, \"test\",  \"test_corpus.txt\")\n",
    "\n",
    "CLASSES_PATH = os.path.join(DATA_DIR, \"classes.txt\")\n",
    "HIER_PATH    = os.path.join(DATA_DIR, \"class_hierarchy.txt\")\n",
    "KEYWORD_PATH = os.path.join(DATA_DIR, \"class_related_keywords.txt\")\n",
    "\n",
    "ART_DIR = os.path.join(PROJECT_ROOT, \"artifacts_Experiment4\")\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "NUM_CLASSES = 531\n",
    "MIN_LABELS = 2\n",
    "MAX_LABELS = 3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dd0c6eb-790e-41ce-b91e-0651fe0da103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:11.567848Z",
     "iopub.status.busy": "2025-12-19T13:04:11.567556Z",
     "iopub.status.idle": "2025-12-19T13:04:12.449087Z",
     "shell.execute_reply": "2025-12-19T13:04:12.448526Z",
     "shell.execute_reply.started": "2025-12-19T13:04:11.567826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 29487 test: 19658\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2: Clean + Load Corpus\n",
    "# =========================\n",
    "\n",
    "TAG_RE = re.compile(r\"<[^>]+>\")\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s or \"\"\n",
    "    s = TAG_RE.sub(\" \", s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def load_corpus(path: str):\n",
    "    pid2text = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\"\\t\", 1)\n",
    "            if len(parts) == 2:\n",
    "                pid, text = parts\n",
    "                pid2text[pid] = clean_text(text)\n",
    "    return pid2text\n",
    "\n",
    "pid2text_train = load_corpus(TRAIN_CORPUS_PATH)\n",
    "pid2text_test  = load_corpus(TEST_CORPUS_PATH)\n",
    "id_list_test   = list(pid2text_test.keys())\n",
    "\n",
    "print(\"train:\", len(pid2text_train), \"test:\", len(pid2text_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ad8e5d9-e087-4da4-bbe2-57f468b38fb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:14.205060Z",
     "iopub.status.busy": "2025-12-19T13:04:14.204786Z",
     "iopub.status.idle": "2025-12-19T13:04:14.241205Z",
     "shell.execute_reply": "2025-12-19T13:04:14.240607Z",
     "shell.execute_reply.started": "2025-12-19T13:04:14.205038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num classes loaded: 531\n",
      "A_hat: torch.Size([531, 531])\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 3: Load classes (robust) + hierarchy + adjacency matrix A_hat\n",
    "# =========================\n",
    "\n",
    "def load_classes(path):\n",
    "    \"\"\"\n",
    "    Supports:\n",
    "      - 'id<TAB>class name with spaces'\n",
    "      - OR 'id<space>class name with spaces'\n",
    "      - OR name-only per line\n",
    "    \"\"\"\n",
    "    name2id, id2name = {}, {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            m = re.match(r\"^(\\d+)\\s+(.+)$\", line)\n",
    "            if m:\n",
    "                cid = int(m.group(1))\n",
    "                cname = m.group(2).strip()\n",
    "            else:\n",
    "                parts = line.split(\"\\t\")\n",
    "                if len(parts) == 2 and parts[0].isdigit():\n",
    "                    cid = int(parts[0])\n",
    "                    cname = parts[1].strip()\n",
    "                else:\n",
    "                    cid = len(id2name)\n",
    "                    cname = line\n",
    "\n",
    "            name2id[cname] = cid\n",
    "            id2name[cid] = cname\n",
    "\n",
    "    return name2id, id2name\n",
    "\n",
    "name2id, id2name = load_classes(CLASSES_PATH)\n",
    "assert len(id2name) == NUM_CLASSES, f\"Expected {NUM_CLASSES}, got {len(id2name)}\"\n",
    "print(\"num classes loaded:\", len(id2name))\n",
    "\n",
    "def load_hierarchy(path):\n",
    "    parents = defaultdict(set)  # child -> parents\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            p_str, c_str = line.split(\"\\t\")\n",
    "            p, c = int(p_str), int(c_str)\n",
    "            parents[c].add(p)\n",
    "    return parents\n",
    "\n",
    "parents = load_hierarchy(HIER_PATH)\n",
    "\n",
    "def get_ancestors(cid: int) -> list:\n",
    "    # nearest-first expansion (BFS-ish)\n",
    "    seen = set()\n",
    "    q = [cid]\n",
    "    out = []\n",
    "    while q:\n",
    "        x = q.pop(0)\n",
    "        for p in sorted(list(parents.get(x, []))):\n",
    "            if p not in seen:\n",
    "                seen.add(p)\n",
    "                out.append(p)\n",
    "                q.append(p)\n",
    "    return out\n",
    "\n",
    "def build_label_adj(num_classes, parents_dict, add_self_loop=True, undirected=True):\n",
    "    A = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    for child, ps in parents_dict.items():\n",
    "        for p in ps:\n",
    "            A[p, child] = 1.0\n",
    "            if undirected:\n",
    "                A[child, p] = 1.0\n",
    "    if add_self_loop:\n",
    "        np.fill_diagonal(A, 1.0)\n",
    "\n",
    "    deg = A.sum(axis=1)\n",
    "    deg_inv_sqrt = np.power(deg, -0.5, where=deg > 0)\n",
    "    deg_inv_sqrt[deg == 0] = 0.0\n",
    "    D_inv_sqrt = np.diag(deg_inv_sqrt)\n",
    "    A_hat = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return torch.tensor(A_hat, dtype=torch.float32)\n",
    "\n",
    "A_hat = build_label_adj(NUM_CLASSES, parents).to(device)\n",
    "print(\"A_hat:\", A_hat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e14acf8-557a-48f0-9c68-f0fc72b55566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:15.116245Z",
     "iopub.status.busy": "2025-12-19T13:04:15.115971Z",
     "iopub.status.idle": "2025-12-19T13:04:15.129385Z",
     "shell.execute_reply": "2025-12-19T13:04:15.128910Z",
     "shell.execute_reply.started": "2025-12-19T13:04:15.116217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keyword classes: 531\n",
      "Example: grocery_gourmet_food ['snacks', 'condiments', 'beverages', 'specialty_foods', 'spices', 'cooking_oils', 'baking_ingredients', 'gourmet_chocolates', 'artisanal_cheeses', 'organic_foods']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4: Load class-related keywords (COLON format)\n",
    "# =========================\n",
    "\n",
    "def load_class_keywords(path, id2name):\n",
    "    \"\"\"\n",
    "    Format expected:\n",
    "    class_name:kw1,kw2,kw3,...\n",
    "    \"\"\"\n",
    "    name2id = {v: k for k, v in id2name.items()}\n",
    "    cid2kws = defaultdict(list)\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or \":\" not in line:\n",
    "                continue\n",
    "\n",
    "            cname, rest = line.split(\":\", 1)\n",
    "            cname = cname.strip()\n",
    "\n",
    "            if cname not in name2id:\n",
    "                # IMPORTANT: this prevents silent bugs\n",
    "                continue\n",
    "\n",
    "            cid = name2id[cname]\n",
    "            kws = [clean_text(k) for k in rest.split(\",\")]\n",
    "            kws = [k for k in kws if k]\n",
    "\n",
    "            cid2kws[cid].extend(kws)\n",
    "\n",
    "    # de-duplicate keywords per class\n",
    "    for cid in cid2kws:\n",
    "        cid2kws[cid] = list(dict.fromkeys(cid2kws[cid]))\n",
    "\n",
    "    return cid2kws\n",
    "\n",
    "cid2kws = load_class_keywords(KEYWORD_PATH, id2name)\n",
    "\n",
    "print(\"Loaded keyword classes:\", len(cid2kws))\n",
    "print(\"Example:\", id2name[0], cid2kws.get(0, [])[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e90f50e5-d266-47dc-bd81-ba7efe5b4377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:16.434843Z",
     "iopub.status.busy": "2025-12-19T13:04:16.434594Z",
     "iopub.status.idle": "2025-12-19T13:04:16.464161Z",
     "shell.execute_reply": "2025-12-19T13:04:16.463568Z",
     "shell.execute_reply.started": "2025-12-19T13:04:16.434817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max depth: 3\n",
      "A_hat: torch.Size([531, 531])\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4a: Ancestor expansion helper (core -> expanded)\n",
    "# =========================\n",
    "\n",
    "def load_hierarchy(path):\n",
    "    parents = defaultdict(set)  # child -> parents\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            p_str, c_str = line.split(\"\\t\")\n",
    "            p, c = int(p_str), int(c_str)\n",
    "            parents[c].add(p)\n",
    "    return parents\n",
    "\n",
    "parents = load_hierarchy(HIER_PATH)\n",
    "\n",
    "def get_ancestors(cid: int) -> set:\n",
    "    anc = set()\n",
    "    stack = [cid]\n",
    "    while stack:\n",
    "        x = stack.pop()\n",
    "        for p in parents.get(x, []):\n",
    "            if p not in anc:\n",
    "                anc.add(p)\n",
    "                stack.append(p)\n",
    "    return anc\n",
    "\n",
    "def compute_depths(num_classes: int):\n",
    "    depth = [-1] * num_classes\n",
    "    def dfs(x):\n",
    "        if depth[x] != -1:\n",
    "            return depth[x]\n",
    "        ps = parents.get(x, [])\n",
    "        if not ps:\n",
    "            depth[x] = 0\n",
    "            return 0\n",
    "        depth[x] = 1 + max(dfs(p) for p in ps)\n",
    "        return depth[x]\n",
    "    for i in range(num_classes):\n",
    "        dfs(i)\n",
    "    return depth\n",
    "\n",
    "depths = compute_depths(NUM_CLASSES)\n",
    "print(\"max depth:\", max(depths))\n",
    "\n",
    "def build_label_adj(num_classes, parents_dict, add_self_loop=True, undirected=True):\n",
    "    A = np.zeros((num_classes, num_classes), dtype=np.float32)\n",
    "    for child, ps in parents_dict.items():\n",
    "        for p in ps:\n",
    "            A[p, child] = 1.0\n",
    "            if undirected:\n",
    "                A[child, p] = 1.0\n",
    "    if add_self_loop:\n",
    "        np.fill_diagonal(A, 1.0)\n",
    "\n",
    "    deg = A.sum(axis=1)\n",
    "    deg_inv_sqrt = np.power(deg, -0.5, where=deg>0)\n",
    "    deg_inv_sqrt[deg == 0] = 0.0\n",
    "    D_inv_sqrt = np.diag(deg_inv_sqrt)\n",
    "    A_hat = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "    return torch.tensor(A_hat, dtype=torch.float32)\n",
    "\n",
    "A_hat = build_label_adj(NUM_CLASSES, parents)\n",
    "print(\"A_hat:\", A_hat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95c6d37b-0065-4fb8-abbe-86b9fc84cce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:17.713747Z",
     "iopub.status.busy": "2025-12-19T13:04:17.713521Z",
     "iopub.status.idle": "2025-12-19T13:04:17.728431Z",
     "shell.execute_reply": "2025-12-19T13:04:17.727883Z",
     "shell.execute_reply.started": "2025-12-19T13:04:17.713728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keywords: 4634\n"
     ]
    }
   ],
   "source": [
    "def load_keywords_name_format(path, name2id):\n",
    "    kw2cids = defaultdict(set)\n",
    "    missing = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or \":\" not in line:\n",
    "                continue\n",
    "            cname, rest = line.split(\":\", 1)\n",
    "            cname = cname.strip()\n",
    "            if cname not in name2id:\n",
    "                missing.append(cname)\n",
    "                continue\n",
    "            cid = name2id[cname]\n",
    "            kws = [clean_text(k) for k in rest.split(\",\")]\n",
    "            kws = [k for k in kws if k]\n",
    "            for kw in kws:\n",
    "                kw2cids[kw].add(cid)\n",
    "    if missing:\n",
    "        print(\"WARNING missing class names (showing 10):\", missing[:10])\n",
    "    return kw2cids\n",
    "\n",
    "kw2cids = load_keywords_name_format(KEYWORD_PATH, name2id)\n",
    "print(\"num keywords:\", len(kw2cids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcf4cf20-b08a-457a-b0b4-70848dc277f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:18.599280Z",
     "iopub.status.busy": "2025-12-19T13:04:18.598983Z",
     "iopub.status.idle": "2025-12-19T13:04:31.736835Z",
     "shell.execute_reply": "2025-12-19T13:04:31.735663Z",
     "shell.execute_reply.started": "2025-12-19T13:04:18.599256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train silver labels:   1%|▏         | 370/29487 [00:13<17:07, 28.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m train_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pid, text \u001b[38;5;129;01min\u001b[39;00m tqdm(pid2text_train\u001b[38;5;241m.\u001b[39mitems(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating train silver labels\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 76\u001b[0m     core, expanded \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_labels_core_and_expanded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_LABELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LABELS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m expanded:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[49], line 29\u001b[0m, in \u001b[0;36mpredict_labels_core_and_expanded\u001b[0;34m(text, k_min, k_max)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_labels_core_and_expanded\u001b[39m(text, k_min\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, k_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    core: top-k keyword-matched labels (high confidence)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    expanded: core + all ancestors (hierarchy-consistent training target)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mscore_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scores:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [], []\n",
      "Cell \u001b[0;32mIn[49], line 17\u001b[0m, in \u001b[0;36mscore_doc\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     15\u001b[0m scores \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kw, cids \u001b[38;5;129;01min\u001b[39;00m kw2cids\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mkw_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     18\u001b[0m         w \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(cids)))  \u001b[38;5;66;03m# generic penalty\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m cid \u001b[38;5;129;01min\u001b[39;00m cids:\n",
      "Cell \u001b[0;32mIn[49], line 12\u001b[0m, in \u001b[0;36mkw_match\u001b[0;34m(text, kw)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kw \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _kw_regex_cache:\n\u001b[1;32m     11\u001b[0m     _kw_regex_cache[kw] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mre\u001b[38;5;241m.\u001b[39mescape(kw)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_kw_regex_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5: Silver label generation (core + expanded) + SAVE\n",
    "# =========================\n",
    "\n",
    "_kw_regex_cache = {}\n",
    "\n",
    "def kw_match(text, kw):\n",
    "    if \" \" in kw:\n",
    "        return kw in text\n",
    "    if kw not in _kw_regex_cache:\n",
    "        _kw_regex_cache[kw] = re.compile(rf\"\\b{re.escape(kw)}\\b\")\n",
    "    return _kw_regex_cache[kw].search(text) is not None\n",
    "\n",
    "def score_doc(text):\n",
    "    scores = defaultdict(float)\n",
    "    for kw, cids in kw2cids.items():\n",
    "        if kw_match(text, kw):\n",
    "            w = 1.0 / (1.0 + np.log(1 + len(cids)))  # generic penalty\n",
    "            for cid in cids:\n",
    "                scores[cid] += w\n",
    "    # specificity bonus\n",
    "    return scores\n",
    "\n",
    "def predict_labels_core_and_expanded(text, k_min=2, k_max=3):\n",
    "    \"\"\"\n",
    "    core: top-k keyword-matched labels (high confidence)\n",
    "    expanded: core + all ancestors (hierarchy-consistent training target)\n",
    "    \"\"\"\n",
    "    scores = score_doc(text)\n",
    "    if not scores:\n",
    "        return [], []\n",
    "\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    seed_top = [cid for cid, _ in ranked[:k_max]]\n",
    "\n",
    "    # Candidate set: seed + ancestors (lets parents compete during core selection too)\n",
    "    cand = set(seed_top)\n",
    "    for cid in seed_top:\n",
    "        cand |= get_ancestors(cid)\n",
    "\n",
    "    # Rank candidates: prefer high score; break ties by shallower depth\n",
    "    cand_ranked = sorted(list(cand), key=lambda c: (scores.get(c, 0.0), -depths[c]), reverse=True)\n",
    "\n",
    "    chosen = []\n",
    "    for cid in cand_ranked:\n",
    "        if cid not in chosen:\n",
    "            chosen.append(cid)\n",
    "        if len(chosen) >= k_max:\n",
    "            break\n",
    "\n",
    "    if len(chosen) < k_min:\n",
    "        for cid, _ in ranked:\n",
    "            if cid not in chosen:\n",
    "                chosen.append(cid)\n",
    "            if len(chosen) >= k_min:\n",
    "                break\n",
    "\n",
    "    core = chosen[:k_max]\n",
    "\n",
    "    expanded = set(core)\n",
    "    for cid in core:\n",
    "        expanded |= get_ancestors(cid)\n",
    "    expanded = sorted(expanded)\n",
    "\n",
    "    return core, expanded\n",
    "\n",
    "# Backward-compatible helper: returns expanded labels (same as baseline behavior)\n",
    "def predict_labels(text, k_min=2, k_max=3):\n",
    "    _, expanded = predict_labels_core_and_expanded(text, k_min=k_min, k_max=k_max)\n",
    "    return expanded\n",
    "\n",
    "TRAIN_SILVER_PATH = os.path.join(ART_DIR, \"train_silver_labels.csv\")\n",
    "\n",
    "train_rows = []\n",
    "for pid, text in tqdm(pid2text_train.items(), desc=\"Generating train silver labels\"):\n",
    "    core, expanded = predict_labels_core_and_expanded(text, k_min=MIN_LABELS, k_max=MAX_LABELS)\n",
    "    if not expanded:\n",
    "        continue\n",
    "    train_rows.append({\n",
    "        \"pid\": pid,\n",
    "        \"text\": text,\n",
    "        \"core_labels\": \",\".join(map(str, core)),\n",
    "        \"labels\": \",\".join(map(str, expanded)),\n",
    "    })\n",
    "\n",
    "train_silver_df = pd.DataFrame(train_rows)\n",
    "train_silver_df.to_csv(TRAIN_SILVER_PATH, index=False)\n",
    "\n",
    "print(\"Saved:\", TRAIN_SILVER_PATH)\n",
    "print(\"Train silver samples:\", len(train_silver_df))\n",
    "train_silver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be4f5e47-691d-4432-a004-58ebf56f05d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:35.357825Z",
     "iopub.status.busy": "2025-12-19T13:04:35.357557Z",
     "iopub.status.idle": "2025-12-19T13:04:35.579510Z",
     "shell.execute_reply": "2025-12-19T13:04:35.578502Z",
     "shell.execute_reply.started": "2025-12-19T13:04:35.357805Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './artifacts_Experiment4/train_silver_labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_silver_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_SILVER_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m label_freq \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m train_silver_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './artifacts_Experiment4/train_silver_labels.csv'"
     ]
    }
   ],
   "source": [
    "train_silver_df = pd.read_csv(TRAIN_SILVER_PATH)\n",
    "label_freq = Counter()\n",
    "\n",
    "for s in train_silver_df[\"labels\"]:\n",
    "    for x in str(s).split(\",\"):\n",
    "        label_freq[int(x)] += 1\n",
    "\n",
    "fallback_default = [cid for cid, _ in label_freq.most_common(2)]\n",
    "print(\"Fallback default:\", fallback_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "514f879f-cf74-4d6e-86db-9324a761150b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:04:51.728819Z",
     "iopub.status.busy": "2025-12-19T13:04:51.728517Z",
     "iopub.status.idle": "2025-12-19T13:06:18.380023Z",
     "shell.execute_reply": "2025-12-19T13:06:18.379303Z",
     "shell.execute_reply.started": "2025-12-19T13:04:51.728797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding:  70%|███████   | 427/610 [01:26<00:36,  4.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m train_texts \u001b[38;5;241m=\u001b[39m train_silver_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     29\u001b[0m test_texts  \u001b[38;5;241m=\u001b[39m [pid2text_test[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m id_list_test]\n\u001b[0;32m---> 31\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m X_test  \u001b[38;5;241m=\u001b[39m embed_texts(test_texts,  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     34\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ART_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_bert.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m), X_train)\n",
      "File \u001b[0;32m/opt/conda/envs/esci/lib/python3.9/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 25\u001b[0m, in \u001b[0;36membed_texts\u001b[0;34m(texts, batch_size, max_length)\u001b[0m\n\u001b[1;32m     23\u001b[0m     mask \u001b[38;5;241m=\u001b[39m enc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m     pooled \u001b[38;5;241m=\u001b[39m (out \u001b[38;5;241m*\u001b[39m mask)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m mask\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     vecs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpooled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack(vecs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6: Frozen BERT embeddings for documents (no fine-tuning)\n",
    "# =========================\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"  # general pretrained, not Amazon-finetuned\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "bert.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_texts(texts, batch_size=32, max_length=256):\n",
    "    vecs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        out = bert(**enc).last_hidden_state\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)\n",
    "        pooled = (out * mask).sum(1) / mask.sum(1).clamp(min=1)\n",
    "        vecs.append(pooled.cpu().numpy())\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "train_texts = train_silver_df[\"text\"].astype(str).tolist()\n",
    "test_texts  = [pid2text_test[i] for i in id_list_test]\n",
    "\n",
    "X_train = embed_texts(train_texts, batch_size=32, max_length=256)\n",
    "X_test  = embed_texts(test_texts,  batch_size=32, max_length=256)\n",
    "\n",
    "np.save(os.path.join(ART_DIR, \"train_bert.npy\"), X_train)\n",
    "np.save(os.path.join(ART_DIR, \"test_bert.npy\"),  X_test)\n",
    "json.dump(train_silver_df[\"pid\"].astype(str).tolist(), open(os.path.join(ART_DIR, \"train_ids.json\"), \"w\"))\n",
    "json.dump(id_list_test, open(os.path.join(ART_DIR, \"test_ids.json\"), \"w\"))\n",
    "\n",
    "print(\"Saved embeddings:\", X_train.shape, X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb87a750-7efe-4a23-8486-4c4fb448ff2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:06:20.389641Z",
     "iopub.status.busy": "2025-12-19T13:06:20.389372Z",
     "iopub.status.idle": "2025-12-19T13:06:21.178221Z",
     "shell.execute_reply": "2025-12-19T13:06:21.177575Z",
     "shell.execute_reply.started": "2025-12-19T13:06:20.389620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding labels: 100%|██████████| 9/9 [00:00<00:00, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_label: torch.Size([531, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 7: Build E_label (label embeddings) from class name + keywords (frozen BERT)\n",
    "# =========================\n",
    "\n",
    "def build_label_texts(id2name, cid2kws, topk=8):\n",
    "    texts = []\n",
    "    for cid in range(NUM_CLASSES):\n",
    "        name = id2name[cid]\n",
    "        kws = cid2kws.get(cid, [])[:topk]\n",
    "        texts.append(clean_text(name) + \" ; keywords: \" + \", \".join(kws))\n",
    "    return texts\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_label_texts(texts, batch_size=64, max_length=64):\n",
    "    embs = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding labels\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "        out = bert(**enc).last_hidden_state\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1)\n",
    "        pooled = (out * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1)\n",
    "        embs.append(pooled.detach().cpu())\n",
    "    return torch.cat(embs, dim=0)\n",
    "\n",
    "label_texts = build_label_texts(id2name, cid2kws, topk=8)\n",
    "E_label = embed_label_texts(label_texts)  # (C, 768) on CPU\n",
    "print(\"E_label:\", E_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80296a73-4ebf-4a63-aa45-433a4b794c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:06:24.124372Z",
     "iopub.status.busy": "2025-12-19T13:06:24.124073Z",
     "iopub.status.idle": "2025-12-19T13:06:24.175116Z",
     "shell.execute_reply": "2025-12-19T13:06:24.174539Z",
     "shell.execute_reply.started": "2025-12-19T13:06:24.124349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 138 val batches: 8\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 8: Dataset + train/val split (CORE-AWARE)\n",
    "# =========================\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def labels_str_to_target(labels_str, num_classes=NUM_CLASSES):\n",
    "    y = torch.zeros(num_classes, dtype=torch.float32)\n",
    "    for t in str(labels_str).split(\",\"):\n",
    "        t = t.strip()\n",
    "        if t:\n",
    "            idx = int(t)\n",
    "            if 0 <= idx < num_classes:\n",
    "                y[idx] = 1.0\n",
    "    return y\n",
    "\n",
    "class SilverEmbDataset(Dataset):\n",
    "    def __init__(self, X, core_label_strs, all_label_strs):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.core_label_strs = list(core_label_strs)\n",
    "        self.all_label_strs  = list(all_label_strs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        y_core = labels_str_to_target(self.core_label_strs[i])\n",
    "        y_all  = labels_str_to_target(self.all_label_strs[i])\n",
    "        return {\"X\": self.X[i], \"y_core\": y_core, \"y\": y_all}\n",
    "\n",
    "X_train = np.load(os.path.join(ART_DIR, \"train_bert.npy\"))\n",
    "X_test  = np.load(os.path.join(ART_DIR, \"test_bert.npy\"))\n",
    "\n",
    "core_strs = train_silver_df[\"core_labels\"].astype(str).tolist()\n",
    "all_strs  = train_silver_df[\"labels\"].astype(str).tolist()\n",
    "\n",
    "assert len(core_strs) == len(all_strs) == len(X_train), f\"Mismatch: core={len(core_strs)} all={len(all_strs)} X={len(X_train)}\"\n",
    "\n",
    "X_tr, X_va, c_tr, c_va, a_tr, a_va = train_test_split(\n",
    "    X_train, core_strs, all_strs, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(SilverEmbDataset(X_tr, c_tr, a_tr), batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(SilverEmbDataset(X_va, c_va, a_va), batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"train batches:\", len(train_loader), \"val batches:\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db990c00-17e6-4f14-9515-a6e9c56ba06d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:06:26.553965Z",
     "iopub.status.busy": "2025-12-19T13:06:26.553696Z",
     "iopub.status.idle": "2025-12-19T13:06:26.759404Z",
     "shell.execute_reply": "2025-12-19T13:06:26.758836Z",
     "shell.execute_reply.started": "2025-12-19T13:06:26.553946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelAttnClassifier(\n",
      "  (doc_proj): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (label_proj): Linear(in_features=768, out_features=256, bias=False)\n",
      "  (label_attn): LabelGAT(\n",
      "    (W): Linear(in_features=256, out_features=256, bias=False)\n",
      "    (a_src): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (a_dst): Linear(in_features=256, out_features=1, bias=False)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 9 (REPLACE): Label Attention model (Parent-child GAT OR Ancestor Path attention)\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "\n",
    "# ---------- Build hierarchy structures ----------\n",
    "# parents: dict child -> set(parents) must already exist (from your Cell 4a)\n",
    "\n",
    "NUM_CLASSES = NUM_CLASSES if \"NUM_CLASSES\" in globals() else 531\n",
    "EMB_DIM = 256\n",
    "\n",
    "# build bidirectional edges for GAT (parent<->child)\n",
    "edges = []\n",
    "for child, ps in parents.items():\n",
    "    for p in ps:\n",
    "        edges.append((p, child))\n",
    "        edges.append((child, p))\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous().to(device)  # [2, E]\n",
    "\n",
    "def build_ancestor_list(parents, num_classes, max_anc=10):\n",
    "    \"\"\"\n",
    "    For each label c, collect up to max_anc ancestors (BFS upward).\n",
    "    Works for DAG: mixes multiple-parent ancestors naturally.\n",
    "    \"\"\"\n",
    "    ancestors = []\n",
    "    for c in range(num_classes):\n",
    "        seen = set()\n",
    "        q = deque(list(parents.get(c, set())))\n",
    "        anc = []\n",
    "        while q and len(anc) < max_anc:\n",
    "            p = q.popleft()\n",
    "            if p in seen:\n",
    "                continue\n",
    "            seen.add(p)\n",
    "            anc.append(p)\n",
    "            for pp in parents.get(p, set()):\n",
    "                if pp not in seen:\n",
    "                    q.append(pp)\n",
    "        ancestors.append(anc)\n",
    "    return ancestors\n",
    "\n",
    "ancestors = build_ancestor_list(parents, NUM_CLASSES, max_anc=10)\n",
    "\n",
    "# ---------- Parent-child attention (GAT-style) ----------\n",
    "class LabelGAT(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.1, use_self_loop=True):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.use_self_loop = use_self_loop\n",
    "        self.W = nn.Linear(dim, dim, bias=False)\n",
    "        self.a_src = nn.Linear(dim, 1, bias=False)\n",
    "        self.a_dst = nn.Linear(dim, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, E, edge_index):\n",
    "        \"\"\"\n",
    "        E: [L, d]\n",
    "        edge_index: [2, E] (src -> dst)\n",
    "        \"\"\"\n",
    "        L, d = E.shape\n",
    "        H = self.W(E)  # [L, d]\n",
    "        src, dst = edge_index[0], edge_index[1]\n",
    "\n",
    "        h_src = H[src]   # [E, d]\n",
    "        h_dst = H[dst]   # [E, d]\n",
    "\n",
    "        e = (self.a_src(h_src) + self.a_dst(h_dst)).squeeze(-1)   # [E]\n",
    "        e = F.leaky_relu(e, negative_slope=0.2)\n",
    "\n",
    "        # segment softmax over incoming edges per dst\n",
    "        attn = torch.zeros_like(e)\n",
    "        order = torch.argsort(dst)\n",
    "        src_s, dst_s, e_s = src[order], dst[order], e[order]\n",
    "\n",
    "        # find segments where dst changes\n",
    "        change = torch.nonzero(dst_s[1:] != dst_s[:-1]).squeeze(-1) + 1\n",
    "        bounds = torch.cat([torch.tensor([0], device=dst_s.device), change, torch.tensor([dst_s.numel()], device=dst_s.device)])\n",
    "\n",
    "        for i in range(bounds.numel() - 1):\n",
    "            a, b = int(bounds[i].item()), int(bounds[i+1].item())\n",
    "            seg = torch.arange(a, b, device=dst_s.device)\n",
    "            seg_a = torch.softmax(e_s[seg], dim=0)\n",
    "            attn[order[seg]] = seg_a\n",
    "\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.zeros_like(H)\n",
    "        out.index_add_(0, dst, h_src * attn.unsqueeze(-1))\n",
    "\n",
    "        if self.use_self_loop:\n",
    "            out = out + H\n",
    "\n",
    "        return self.ln(out)\n",
    "\n",
    "# ---------- Path-based ancestor attention ----------\n",
    "class PathLabelAttn(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.q_proj = nn.Linear(dim, dim, bias=False)\n",
    "        self.k_proj = nn.Linear(dim, dim, bias=False)\n",
    "        self.v_proj = nn.Linear(dim, dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, E, ancestors):\n",
    "        \"\"\"\n",
    "        E: [L, d]\n",
    "        ancestors: list[list[int]]\n",
    "        \"\"\"\n",
    "        L, d = E.shape\n",
    "        Q = self.q_proj(E)\n",
    "        K = self.k_proj(E)\n",
    "        V = self.v_proj(E)\n",
    "\n",
    "        out = torch.zeros_like(E)\n",
    "\n",
    "        for c in range(L):\n",
    "            anc = ancestors[c]\n",
    "            if len(anc) == 0:\n",
    "                out[c] = E[c]\n",
    "                continue\n",
    "\n",
    "            q = Q[c:c+1]   # [1,d]\n",
    "            k = K[anc]     # [A,d]\n",
    "            v = V[anc]     # [A,d]\n",
    "\n",
    "            scores = (q * k).sum(dim=-1) / (d ** 0.5)     # [A]\n",
    "            attn = torch.softmax(scores, dim=0)\n",
    "            attn = self.dropout(attn)\n",
    "\n",
    "            msg = (attn.unsqueeze(-1) * v).sum(dim=0)     # [d]\n",
    "            out[c] = E[c] + msg\n",
    "\n",
    "        return self.ln(out)\n",
    "\n",
    "# ---------- Final classifier with label attention ----------\n",
    "class LabelAttnClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_labels, emb_dim, E_label_768,\n",
    "                 edge_index=None, ancestors=None,\n",
    "                 mode=\"gat\", dropout=0.2):\n",
    "        \"\"\"\n",
    "        mode: \"gat\" (parent-child attention) or \"path\" (ancestor attention)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # document projection (so PCA can use learned repr)\n",
    "        self.doc_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, emb_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # label projection: 768 -> emb_dim\n",
    "        self.label_proj = nn.Linear(E_label_768.shape[1], emb_dim, bias=False)\n",
    "\n",
    "        # keep label text embeddings frozen; only label_proj + attention learn\n",
    "        self.register_buffer(\"E_label_text\", E_label_768.float())\n",
    "\n",
    "        if mode == \"gat\":\n",
    "            assert edge_index is not None\n",
    "            self.label_attn = LabelGAT(emb_dim, dropout=dropout, use_self_loop=True)\n",
    "            self.edge_index = edge_index\n",
    "            self.ancestors = None\n",
    "        elif mode == \"path\":\n",
    "            assert ancestors is not None\n",
    "            self.label_attn = PathLabelAttn(emb_dim, dropout=dropout)\n",
    "            self.ancestors = ancestors\n",
    "            self.edge_index = None\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'gat' or 'path'\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        h = self.doc_proj(X)  # [B, emb_dim]\n",
    "\n",
    "        # label embeddings from text + projection\n",
    "        E0 = self.label_proj(self.E_label_text)  # [C, emb_dim]\n",
    "\n",
    "        # apply hierarchy-aware attention\n",
    "        if self.mode == \"gat\":\n",
    "            E = self.label_attn(E0, self.edge_index)       # [C, emb_dim]\n",
    "        else:\n",
    "            E = self.label_attn(E0, self.ancestors)        # [C, emb_dim]\n",
    "\n",
    "        logits = h @ E.t()  # [B, C]\n",
    "        return logits\n",
    "\n",
    "# ---------- Instantiate model ----------\n",
    "# E_label from your Cell 7: (C, 768) on CPU\n",
    "E_label_768 = E_label.to(device)\n",
    "\n",
    "# Choose one:\n",
    "ATTN_MODE = \"gat\"   # \"gat\" for parent-child attention, or \"path\" for ancestor path attention\n",
    "\n",
    "model = LabelAttnClassifier(\n",
    "    input_dim=X_train.shape[1],\n",
    "    num_labels=NUM_CLASSES,\n",
    "    emb_dim=EMB_DIM,\n",
    "    E_label_768=E_label_768,\n",
    "    edge_index=edge_index if ATTN_MODE == \"gat\" else None,\n",
    "    ancestors=ancestors if ATTN_MODE == \"path\" else None,\n",
    "    mode=ATTN_MODE,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d7ff8-c71b-4fc3-9b82-e1835197c499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09681a1f-e183-4ff7-b348-e49b3a68401e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35a5081d-97d8-418f-9c52-d0534271f57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:14.433453Z",
     "iopub.status.busy": "2025-12-19T13:07:14.433101Z",
     "iopub.status.idle": "2025-12-19T13:10:36.084364Z",
     "shell.execute_reply": "2025-12-19T13:10:36.083833Z",
     "shell.execute_reply.started": "2025-12-19T13:07:14.433431Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 138/138 [00:19<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train loss: 0.3121 | val sample-F1: 0.0249\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 138/138 [00:19<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train loss: 0.0517 | val sample-F1: 0.0249\n",
      "  ⏳ no improvement (1/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 138/138 [00:19<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train loss: 0.0476 | val sample-F1: 0.2286\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 138/138 [00:19<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train loss: 0.0439 | val sample-F1: 0.2286\n",
      "  ⏳ no improvement (1/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 138/138 [00:19<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train loss: 0.0424 | val sample-F1: 0.2286\n",
      "  ⏳ no improvement (2/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 138/138 [00:19<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] train loss: 0.0414 | val sample-F1: 0.2286\n",
      "  ⏳ no improvement (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 138/138 [00:19<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] train loss: 0.0409 | val sample-F1: 0.2286\n",
      "  ⏳ no improvement (4/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 138/138 [00:19<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] train loss: 0.0406 | val sample-F1: 0.2286\n",
      "  ⏳ no improvement (5/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 138/138 [00:19<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] train loss: 0.0400 | val sample-F1: 0.2287\n",
      "  ✅ improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 138/138 [00:19<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] train loss: 0.0395 | val sample-F1: 0.2288\n",
      "  ✅ improved\n",
      "Loaded best model. best val sample-F1: 0.22876928746700287\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 10: Training (proper) + evaluation with 2–3 constraint\n",
    "# =========================\n",
    "\n",
    "import copy\n",
    "\n",
    "def sample_f1_score(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    tp = (y_true * y_pred).sum(axis=1)\n",
    "    fp = ((1 - y_true) * y_pred).sum(axis=1)\n",
    "    fn = (y_true * (1 - y_pred)).sum(axis=1)\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn + eps)\n",
    "    return float(np.mean(f1))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sample_f1(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    for batch in loader:\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].cpu().numpy()\n",
    "\n",
    "        logits = model(Xb).cpu().numpy()\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "        yhat = np.zeros_like(probs, dtype=np.float32)\n",
    "        for i in range(probs.shape[0]):\n",
    "            p = probs[i]\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            yhat[i, chosen] = 1.0\n",
    "\n",
    "        all_true.append(yb)\n",
    "        all_pred.append(yhat)\n",
    "\n",
    "    YT = np.vstack(all_true)\n",
    "    YP = np.vstack(all_pred)\n",
    "    return sample_f1_score(YT, YP)\n",
    "\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "\n",
    "THR = 0.35  # try 0.25~0.40 later\n",
    "EPOCHS = 10\n",
    "patience = 8\n",
    "pat = 0\n",
    "best_val = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].to(device)\n",
    "\n",
    "        loss = crit(model(Xb), yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    train_loss = total / len(train_loader)\n",
    "    val_f1 = evaluate_sample_f1(model, val_loader, device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "\n",
    "    print(f\"[Epoch {epoch}] train loss: {train_loss:.4f} | val sample-F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val:\n",
    "        best_val = val_f1\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        pat = 0\n",
    "        print(\"  ✅ improved\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        print(f\"  ⏳ no improvement ({pat}/{patience})\")\n",
    "        if pat >= patience:\n",
    "            print(\"[Early Stopping]\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best model. best val sample-F1:\", best_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34269c33-21c2-4282-908f-66aaa108d24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:11:15.629484Z",
     "iopub.status.busy": "2025-12-19T13:11:15.629197Z",
     "iopub.status.idle": "2025-12-19T13:11:17.308754Z",
     "shell.execute_reply": "2025-12-19T13:11:17.308160Z",
     "shell.execute_reply.started": "2025-12-19T13:11:15.629465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_final_bert_labelgcn.csv rows: 19658\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 11: Predict test + write Kaggle submission (2–3 labels guaranteed)\n",
    "# =========================\n",
    "\n",
    "id_list_test = json.load(open(os.path.join(ART_DIR, \"test_ids.json\")))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(model(torch.tensor(X_test, dtype=torch.float32).to(device))).cpu().numpy()\n",
    "\n",
    "def probs_to_labels_adaptive(p, thr=0.35, min_l=2, max_l=3):\n",
    "    idx = np.argsort(p)[::-1]\n",
    "    chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "    if len(chosen) < min_l:\n",
    "        chosen = idx[:min_l].tolist()\n",
    "    chosen = chosen[:max_l]\n",
    "    return sorted(chosen)\n",
    "\n",
    "pred_labels = [probs_to_labels_adaptive(p, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS) for p in probs]\n",
    "\n",
    "SUBMISSION_PATH = \"submission_final_bert_labelgcn.csv\"\n",
    "with open(SUBMISSION_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])  # competition-required header\n",
    "    for id_, labs in zip(id_list_test, pred_labels):\n",
    "        w.writerow([id_, \",\".join(map(str, labs))])\n",
    "\n",
    "print(\"Saved:\", SUBMISSION_PATH, \"rows:\", len(pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2f7c7c1-1014-4566-9aba-c9fb0bd09957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:11:19.752809Z",
     "iopub.status.busy": "2025-12-19T13:11:19.752525Z",
     "iopub.status.idle": "2025-12-19T13:11:21.450362Z",
     "shell.execute_reply": "2025-12-19T13:11:21.449773Z",
     "shell.execute_reply.started": "2025-12-19T13:11:19.752789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: submission_5_GAT.csv rows: 19658\n"
     ]
    }
   ],
   "source": [
    "import csv, json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "X_test = np.load(\"artifacts_Experiment4/test_bert.npy\")\n",
    "id_list_test = json.load(open(\"artifacts_Experiment4/test_ids.json\"))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    probs = torch.sigmoid(\n",
    "        model(torch.tensor(X_test, dtype=torch.float32).to(device))\n",
    "    ).cpu().numpy()\n",
    "\n",
    "def probs_to_labels_adaptive(p, thr=0.35, min_l=2, max_l=3):\n",
    "    idx = np.argsort(p)[::-1]\n",
    "    chosen = [i for i in idx[:50] if p[i] >= thr]\n",
    "    if len(chosen) < min_l:\n",
    "        chosen = idx[:min_l].tolist()\n",
    "    chosen = chosen[:max_l]\n",
    "    return sorted(chosen)\n",
    "\n",
    "pred_labels = [probs_to_labels_adaptive(p, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS) for p in probs]\n",
    "\n",
    "SUBMISSION_PATH = \"submission_5_GAT.csv\"\n",
    "with open(SUBMISSION_PATH, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"id\", \"label\"])\n",
    "    for id_, labs in zip(id_list_test, pred_labels):\n",
    "        w.writerow([id_, \",\".join(map(str, labs))])\n",
    "\n",
    "print(\"Saved:\", SUBMISSION_PATH, \"rows:\", len(pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a7254-eea3-45cb-b425-f25b380b2379",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.012077Z",
     "iopub.status.idle": "2025-12-19T13:04:02.012254Z",
     "shell.execute_reply": "2025-12-19T13:04:02.012171Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.012162Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# (baseline crit kept for reference)\n",
    "crit = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3)\n",
    "\n",
    "THR = 0.35      # later we will try 0.25~0.40\n",
    "EPOCHS = 50\n",
    "patience = 5\n",
    "pat = 0\n",
    "best_val = -1.0\n",
    "best_state = None\n",
    "\n",
    "def sample_f1_score(y_true, y_pred):\n",
    "    eps = 1e-9\n",
    "    tp = (y_true * y_pred).sum(axis=1)\n",
    "    fp = ((1 - y_true) * y_pred).sum(axis=1)\n",
    "    fn = (y_true * (1 - y_pred)).sum(axis=1)\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn + eps)\n",
    "    return float(np.mean(f1))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_sample_f1(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].cpu().numpy()\n",
    "\n",
    "        logits = model(Xb).cpu().numpy()\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "\n",
    "        yhat = np.zeros_like(probs, dtype=np.float32)\n",
    "        for i in range(probs.shape[0]):\n",
    "            p = probs[i]\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            yhat[i, chosen] = 1.0\n",
    "\n",
    "        all_true.append(yb)\n",
    "        all_pred.append(yhat)\n",
    "\n",
    "    YT = np.vstack(all_true)\n",
    "    YP = np.vstack(all_pred)\n",
    "    return sample_f1_score(YT, YP)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        yb = batch[\"y\"].to(device)\n",
    "\n",
    "        W_CORE = 1.0  # weight for core (keyword) labels\n",
    "        W_AUX  = 0.4  # weight for ancestor-expanded labels\n",
    "\n",
    "        logits = model(Xb)\n",
    "        y_all  = yb\n",
    "        y_core = batch[\"y_core\"].to(device)\n",
    "\n",
    "        loss_elem = F.binary_cross_entropy_with_logits(logits, y_all, reduction=\"none\")\n",
    "        y_aux = (y_all - y_core).clamp(0, 1)\n",
    "\n",
    "        weight = torch.ones_like(loss_elem)\n",
    "        weight = weight + (W_CORE - 1.0) * y_core + (W_AUX - 1.0) * y_aux\n",
    "\n",
    "        loss = (loss_elem * weight).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "\n",
    "    train_loss = total / len(train_loader)\n",
    "    val_f1 = evaluate_sample_f1(model, val_loader, device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "    print(f\"[Epoch {epoch}] train loss: {train_loss:.4f} | val sample-F1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_val:\n",
    "        best_val = val_f1\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        pat = 0\n",
    "        print(\"  ✅ improved\")\n",
    "    else:\n",
    "        pat += 1\n",
    "        print(f\"  ⏳ no improvement ({pat}/{patience})\")\n",
    "        if pat >= patience:\n",
    "            print(\"[Early Stopping]\")\n",
    "            break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best model. best val sample-F1:\", best_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff84e8-056d-4aa8-bacc-e17df3ec9b85",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.012582Z",
     "iopub.status.idle": "2025-12-19T13:04:02.012758Z",
     "shell.execute_reply": "2025-12-19T13:04:02.012676Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.012668Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 13a: Soft targets Q (teacher) for self-training\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "TEMP = 2.0      # >1 softens probabilities\n",
    "LAMBDA = 0.7    # mixing weight toward teacher (0..1)\n",
    "\n",
    "NUM_CLASSES = NUM_CLASSES if \"NUM_CLASSES\" in globals() else 531\n",
    "\n",
    "def labels_strs_to_matrix(label_strs, num_classes):\n",
    "    Y = np.zeros((len(label_strs), num_classes), dtype=np.float32)\n",
    "    for i, s in enumerate(label_strs):\n",
    "        s = str(s)\n",
    "        if (not s) or (s == \"nan\"):\n",
    "            continue\n",
    "        for t in s.split(\",\"):\n",
    "            t = t.strip()\n",
    "            if t:\n",
    "                idx = int(t)\n",
    "                if 0 <= idx < num_classes:\n",
    "                    Y[i, idx] = 1.0\n",
    "    return Y\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_probs_temp(model, X_np, T=2.0, batch_size=256, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    for i in tqdm(range(0, len(X_np), batch_size), desc=\"Teacher predicting\", leave=False):\n",
    "        xb = torch.tensor(X_np[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        logits = model(xb) / T\n",
    "        p = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "    return np.vstack(probs)\n",
    "\n",
    "# Requires you already have: X_tr, X_va, a_tr, a_va from your train/val split cell\n",
    "Y_tr_hard = labels_strs_to_matrix(a_tr, NUM_CLASSES)\n",
    "Y_va_hard = labels_strs_to_matrix(a_va, NUM_CLASSES)\n",
    "\n",
    "P_tr = predict_probs_temp(model, X_tr, T=TEMP, batch_size=256, device=device)\n",
    "P_va = predict_probs_temp(model, X_va, T=TEMP, batch_size=256, device=device)\n",
    "\n",
    "Q_tr = (1.0 - LAMBDA) * Y_tr_hard + LAMBDA * P_tr\n",
    "Q_va = (1.0 - LAMBDA) * Y_va_hard + LAMBDA * P_va\n",
    "\n",
    "print(\"Q_tr:\", Q_tr.shape, \"Q_va:\", Q_va.shape)\n",
    "print(\"Q_tr range:\", float(Q_tr.min()), float(Q_tr.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafa108-ad75-46b5-9a17-bf8847e67cf9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.013056Z",
     "iopub.status.idle": "2025-12-19T13:04:02.013230Z",
     "shell.execute_reply": "2025-12-19T13:04:02.013150Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.013142Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 13b: DataLoaders for soft self-training (Q)\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SoftTargetDataset(Dataset):\n",
    "    def __init__(self, X_np, Q_np):\n",
    "        self.X = torch.tensor(X_np, dtype=torch.float32)\n",
    "        self.Q = torch.tensor(Q_np, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\"X\": self.X[i], \"q\": self.Q[i]}\n",
    "\n",
    "train_loader_soft = DataLoader(SoftTargetDataset(X_tr, Q_tr), batch_size=128, shuffle=True)\n",
    "val_loader_soft   = DataLoader(SoftTargetDataset(X_va, Q_va), batch_size=256, shuffle=False)\n",
    "\n",
    "print(\"soft train batches:\", len(train_loader_soft), \"soft val batches:\", len(val_loader_soft))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2871b9-4c71-483c-b8e1-1d8ffcc909c5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.014011Z",
     "iopub.status.idle": "2025-12-19T13:04:02.014185Z",
     "shell.execute_reply": "2025-12-19T13:04:02.014103Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.014095Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 13c (REPLACE): Stage-2 self-training with CONFIDENCE WEIGHTING + entropy regularization\n",
    "# =========================\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "EPOCHS_STAGE2 = 5          # keep short to avoid confirmation bias\n",
    "LR_STAGE2 = 5e-4           # smaller LR for stability\n",
    "\n",
    "# confidence weighting hyperparams\n",
    "GAMMA_CONF = 3.0           # higher => downweight uncertain q more strongly\n",
    "MIN_W = 0.05               # avoid zero gradients\n",
    "MAX_W = 1.0\n",
    "\n",
    "# entropy regularization (prevents overconfident logits)\n",
    "LAMBDA_ENT = 0.02          # 0.005~0.02 good range\n",
    "\n",
    "opt2 = torch.optim.AdamW(model.parameters(), lr=LR_STAGE2)\n",
    "\n",
    "def bernoulli_entropy(p, eps=1e-6):\n",
    "    p = p.clamp(eps, 1 - eps)\n",
    "    return -(p * torch.log(p) + (1 - p) * torch.log(1 - p))\n",
    "\n",
    "def conf_weight_from_q(q, gamma=2.0, min_w=0.05, max_w=1.0):\n",
    "    \"\"\"\n",
    "    q in [0,1]. We want:\n",
    "      - weight high when q near 0 or 1 (confident)\n",
    "      - weight low when q near 0.5 (uncertain)\n",
    "    Simple confidence score: conf = |q-0.5|*2 in [0,1]\n",
    "    Then apply power gamma to sharpen.\n",
    "    \"\"\"\n",
    "    conf = (q - 0.5).abs() * 2.0\n",
    "    w = conf.pow(gamma)\n",
    "    return w.clamp(min_w, max_w)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_soft_loss(model, loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        xb = batch[\"X\"].to(device)\n",
    "        q  = batch[\"q\"].to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        bce_elem = F.binary_cross_entropy_with_logits(logits, q, reduction=\"none\")\n",
    "        w = conf_weight_from_q(q, gamma=GAMMA_CONF, min_w=MIN_W, max_w=MAX_W)\n",
    "        loss = (bce_elem * w).mean()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        total += loss.item() * bs\n",
    "        n += bs\n",
    "    return total / max(n, 1)\n",
    "\n",
    "def train_one_epoch_conf_st(model, loader, opt, device=\"cuda\"):\n",
    "    model.train()\n",
    "    total, n = 0.0, 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Stage2 Train (conf-weighted)\", leave=False):\n",
    "        xb = batch[\"X\"].to(device)\n",
    "        q  = batch[\"q\"].to(device)\n",
    "\n",
    "        logits = model(xb)\n",
    "        p = torch.sigmoid(logits)\n",
    "\n",
    "        # (1) confidence-weighted soft-target BCE  (== KL(q||p) up to constant, for Bernoulli)\n",
    "        bce_elem = F.binary_cross_entropy_with_logits(logits, q, reduction=\"none\")\n",
    "        w = conf_weight_from_q(q, gamma=GAMMA_CONF, min_w=MIN_W, max_w=MAX_W)\n",
    "        loss_soft = (bce_elem * w).mean()\n",
    "\n",
    "        # (2) entropy regularization: discourage overconfident predictions\n",
    "        ent = bernoulli_entropy(p).mean()\n",
    "        loss = loss_soft + LAMBDA_ENT * ent\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        total += loss_soft.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return total / max(n, 1)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "best_state = None\n",
    "stage2_train_losses = []\n",
    "stage2_val_losses = []\n",
    "\n",
    "for ep in range(1, EPOCHS_STAGE2 + 1):\n",
    "    tr = train_one_epoch_conf_st(model, train_loader_soft, opt2, device=device)\n",
    "    va = eval_soft_loss(model, val_loader_soft, device=device)\n",
    "\n",
    "    stage2_train_losses.append(tr)\n",
    "    stage2_val_losses.append(va)\n",
    "\n",
    "    print(f\"[Stage2 ConfST] epoch {ep}/{EPOCHS_STAGE2} | train={tr:.4f} | val={va:.4f}\")\n",
    "\n",
    "    if va < best_val:\n",
    "        best_val = va\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best Stage-2 model (confidence-weighted).\")\n",
    "\n",
    "# Plot Stage-2 losses (stability)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(stage2_train_losses, label=\"train\")\n",
    "plt.plot(stage2_val_losses, label=\"val\")\n",
    "plt.title(\"Stage-2 (Conf-weighted) Soft Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0695d1-7947-4b03-834b-f51a60df2289",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.016657Z",
     "iopub.status.idle": "2025-12-19T13:04:02.016832Z",
     "shell.execute_reply": "2025-12-19T13:04:02.016751Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.016742Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 12 (UPDATE): HVR + Parent Recall (after training)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_label_lists_rule(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    for batch in tqdm(loader, desc=\"Predicting for HVR\", leave=False):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        probs = torch.sigmoid(model(Xb)).detach().cpu().numpy()  # stable\n",
    "\n",
    "        for p in probs:\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            all_preds.append(list(map(int, chosen)))\n",
    "    return all_preds\n",
    "\n",
    "def compute_depths(num_classes, parents):\n",
    "    depths = np.full(num_classes, -1, dtype=int)\n",
    "    roots = [c for c in range(num_classes) if len(parents.get(c, set())) == 0]\n",
    "\n",
    "    from collections import deque\n",
    "    q = deque(roots)\n",
    "    for r in roots:\n",
    "        depths[r] = 0\n",
    "\n",
    "    children = {i: [] for i in range(num_classes)}\n",
    "    for child, ps in parents.items():\n",
    "        for p in ps:\n",
    "            children[p].append(child)\n",
    "\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in children[u]:\n",
    "            nd = depths[u] + 1\n",
    "            if depths[v] == -1 or nd < depths[v]:\n",
    "                depths[v] = nd\n",
    "                q.append(v)\n",
    "\n",
    "    depths[depths == -1] = 0\n",
    "    return depths\n",
    "\n",
    "def compute_hvr(pred_labels, parents):\n",
    "    total_child_preds = 0\n",
    "    violations = 0\n",
    "    for labs in pred_labels:\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue\n",
    "            total_child_preds += 1\n",
    "            if len(S.intersection(ps)) == 0:\n",
    "                violations += 1\n",
    "    return violations / max(total_child_preds, 1), violations, total_child_preds\n",
    "\n",
    "def parent_recall(pred_labels, parents):\n",
    "    total_child_preds = 0\n",
    "    ok = 0\n",
    "    for labs in pred_labels:\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue\n",
    "            total_child_preds += 1\n",
    "            if len(S.intersection(ps)) > 0:\n",
    "                ok += 1\n",
    "    return ok / max(total_child_preds, 1)\n",
    "\n",
    "def hvr_by_depth(pred_labels, parents, depths, max_depth=10):\n",
    "    viol = np.zeros(max_depth+1, dtype=int)\n",
    "    tot  = np.zeros(max_depth+1, dtype=int)\n",
    "    for labs in pred_labels:\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue\n",
    "            d = int(min(depths[c], max_depth))\n",
    "            tot[d] += 1\n",
    "            if len(S.intersection(ps)) == 0:\n",
    "                viol[d] += 1\n",
    "    rate = viol / np.maximum(tot, 1)\n",
    "    return rate, viol, tot\n",
    "\n",
    "pred_labels = predict_label_lists_rule(model, val_loader, device=device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "\n",
    "depths = compute_depths(NUM_CLASSES, parents)\n",
    "hvr, v_cnt, child_cnt = compute_hvr(pred_labels, parents)\n",
    "pr = parent_recall(pred_labels, parents)\n",
    "\n",
    "print(f\"HVR = {hvr:.4f}  (violations={v_cnt} / child_preds={child_cnt})\")\n",
    "print(f\"Parent Recall = {pr:.4f}\")\n",
    "\n",
    "rate, viol, tot = hvr_by_depth(pred_labels, parents, depths, max_depth=10)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(np.arange(len(rate)), rate)\n",
    "plt.xlabel(\"Depth (clipped at 10)\")\n",
    "plt.ylabel(\"Hierarchy Violation Rate\")\n",
    "plt.title(\"HVR by Depth (after training)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd631e9-1503-47a1-9282-afbba18f5558",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.014460Z",
     "iopub.status.idle": "2025-12-19T13:04:02.014632Z",
     "shell.execute_reply": "2025-12-19T13:04:02.014552Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.014543Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Post-Training: HVR evaluation (val) - stable sigmoid\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_label_lists_rule(model, loader, device, thr=0.35, min_l=2, max_l=3):\n",
    "    \"\"\"\n",
    "    Same rule as your evaluate_sample_f1 / submission:\n",
    "    threshold + ensure min_l + cap max_l\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    for batch in tqdm(loader, desc=\"Predicting for HVR\", leave=False):\n",
    "        Xb = batch[\"X\"].to(device)\n",
    "        probs = torch.sigmoid(model(Xb)).detach().cpu().numpy()  # ✅ stable\n",
    "\n",
    "        for p in probs:\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            all_preds.append(list(map(int, chosen)))\n",
    "    return all_preds\n",
    "\n",
    "def compute_depths(num_classes, parents):\n",
    "    depths = np.full(num_classes, -1, dtype=int)\n",
    "    roots = [c for c in range(num_classes) if len(parents.get(c, set())) == 0]\n",
    "\n",
    "    from collections import deque\n",
    "    q = deque(roots)\n",
    "    for r in roots:\n",
    "        depths[r] = 0\n",
    "\n",
    "    children = {i: [] for i in range(num_classes)}\n",
    "    for child, ps in parents.items():\n",
    "        for p in ps:\n",
    "            children[p].append(child)\n",
    "\n",
    "    while q:\n",
    "        u = q.popleft()\n",
    "        for v in children[u]:\n",
    "            nd = depths[u] + 1\n",
    "            if depths[v] == -1 or nd < depths[v]:\n",
    "                depths[v] = nd\n",
    "                q.append(v)\n",
    "\n",
    "    depths[depths == -1] = 0\n",
    "    return depths\n",
    "\n",
    "def compute_hvr(pred_labels, parents):\n",
    "    total_child_preds = 0\n",
    "    violations = 0\n",
    "    for labs in pred_labels:\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue\n",
    "            total_child_preds += 1\n",
    "            if len(S.intersection(ps)) == 0:\n",
    "                violations += 1\n",
    "    return violations / max(total_child_preds, 1), violations, total_child_preds\n",
    "\n",
    "def hvr_by_depth(pred_labels, parents, depths, max_depth=10):\n",
    "    viol = np.zeros(max_depth+1, dtype=int)\n",
    "    tot  = np.zeros(max_depth+1, dtype=int)\n",
    "\n",
    "    for labs in pred_labels:\n",
    "        S = set(labs)\n",
    "        for c in labs:\n",
    "            ps = parents.get(c, set())\n",
    "            if len(ps) == 0:\n",
    "                continue\n",
    "            d = int(min(depths[c], max_depth))\n",
    "            tot[d] += 1\n",
    "            if len(S.intersection(ps)) == 0:\n",
    "                viol[d] += 1\n",
    "\n",
    "    rate = viol / np.maximum(tot, 1)\n",
    "    return rate, viol, tot\n",
    "\n",
    "pred_labels = predict_label_lists_rule(model, val_loader, device=device, thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS)\n",
    "\n",
    "depths = compute_depths(NUM_CLASSES, parents)\n",
    "hvr, v_cnt, child_cnt = compute_hvr(pred_labels, parents)\n",
    "print(f\"HVR = {hvr:.4f}  (violations={v_cnt} / child_preds={child_cnt})\")\n",
    "\n",
    "rate, viol, tot = hvr_by_depth(pred_labels, parents, depths, max_depth=10)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.bar(np.arange(len(rate)), rate)\n",
    "plt.xlabel(\"Depth (clipped at 10)\")\n",
    "plt.ylabel(\"Hierarchy Violation Rate\")\n",
    "plt.title(\"HVR by Taxonomy Depth (after training)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87c27d-e8f2-41ed-bcfd-23bfa690e831",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.014980Z",
     "iopub.status.idle": "2025-12-19T13:04:02.015155Z",
     "shell.execute_reply": "2025-12-19T13:04:02.015073Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.015064Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install openTSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b8ebd-bed5-4e67-a728-620a2b0e31f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.015530Z",
     "iopub.status.idle": "2025-12-19T13:04:02.015706Z",
     "shell.execute_reply": "2025-12-19T13:04:02.015623Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.015614Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 13 (UPDATE): PCA + t-SNE (learned doc repr + labels)\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_doc_repr(model, X_np, device=\"cuda\", batch_size=256):\n",
    "    model.eval()\n",
    "    reps = []\n",
    "    for i in range(0, len(X_np), batch_size):\n",
    "        xb = torch.tensor(X_np[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        h = model.doc_proj(xb)  # learned doc repr\n",
    "        reps.append(h.detach().cpu().numpy())\n",
    "    return np.vstack(reps)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_top1(model, X_np, device=\"cuda\", batch_size=256):\n",
    "    model.eval()\n",
    "    top1 = []\n",
    "    for i in range(0, len(X_np), batch_size):\n",
    "        xb = torch.tensor(X_np[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        probs = torch.sigmoid(model(xb)).detach().cpu().numpy()\n",
    "        top1.extend(list(np.argmax(probs, axis=1).astype(int)))\n",
    "    return np.array(top1, dtype=int)\n",
    "\n",
    "H_docs = get_doc_repr(model, X_va, device=device, batch_size=256)\n",
    "doc_top1 = predict_top1(model, X_va, device=device, batch_size=256)\n",
    "\n",
    "# label embeddings to visualize: use projected + attended E from the model\n",
    "with torch.no_grad():\n",
    "    E0 = model.label_proj(model.E_label_text).detach()  # [C, d]\n",
    "    if model.mode == \"gat\":\n",
    "        E_vis = model.label_attn(E0, model.edge_index).detach().cpu().numpy()\n",
    "    else:\n",
    "        E_vis = model.label_attn(E0, model.ancestors).detach().cpu().numpy()\n",
    "\n",
    "print(\"Doc repr:\", H_docs.shape, \"| unique top1:\", len(np.unique(doc_top1)))\n",
    "print(\"Label repr:\", E_vis.shape)\n",
    "\n",
    "# PCA Docs\n",
    "H_pca = PCA(n_components=2, random_state=42).fit_transform(H_docs)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(H_pca[:,0], H_pca[:,1], s=6, c=doc_top1)\n",
    "plt.title(\"PCA: Learned document repr (colored by top-1 pred)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# PCA Labels\n",
    "E_pca = PCA(n_components=2, random_state=42).fit_transform(E_vis)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(E_pca[:,0], E_pca[:,1], s=10)\n",
    "plt.title(\"PCA: Label repr (after hierarchy attention)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.show()\n",
    "\n",
    "# t-SNE Docs (subsample)\n",
    "MAX_DOCS_TSNE = 2000\n",
    "if len(H_docs) > MAX_DOCS_TSNE:\n",
    "    idx = np.random.RandomState(42).choice(len(H_docs), MAX_DOCS_TSNE, replace=False)\n",
    "    H_in = H_docs[idx]\n",
    "    c_in = doc_top1[idx]\n",
    "else:\n",
    "    H_in = H_docs\n",
    "    c_in = doc_top1\n",
    "\n",
    "H_tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"pca\", random_state=42).fit_transform(H_in)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(H_tsne[:,0], H_tsne[:,1], s=8, c=c_in)\n",
    "plt.title(\"t-SNE: Learned document repr (colored by top-1 pred)\")\n",
    "plt.xlabel(\"tSNE-1\"); plt.ylabel(\"tSNE-2\")\n",
    "plt.show()\n",
    "\n",
    "# t-SNE Labels\n",
    "E_tsne = TSNE(n_components=2, perplexity=30, learning_rate=\"auto\", init=\"pca\", random_state=42).fit_transform(E_vis)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(E_tsne[:,0], E_tsne[:,1], s=10)\n",
    "plt.title(\"t-SNE: Label repr (after hierarchy attention)\")\n",
    "plt.xlabel(\"tSNE-1\"); plt.ylabel(\"tSNE-2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0255c8a-dd8b-4791-9550-d5e6076387d1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T13:04:02.016145Z",
     "iopub.status.idle": "2025-12-19T13:04:02.016323Z",
     "shell.execute_reply": "2025-12-19T13:04:02.016241Z",
     "shell.execute_reply.started": "2025-12-19T13:04:02.016232Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Submission (UPDATE): stable sigmoid + sorted labels + pid column\n",
    "# =========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os, json\n",
    "\n",
    "X_test = np.load(os.path.join(ART_DIR, \"test_bert.npy\"))\n",
    "test_ids = json.load(open(os.path.join(ART_DIR, \"test_ids.json\"), \"r\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_test_labels_rule(model, X_np, device=\"cuda\",\n",
    "                             thr=0.35, min_l=2, max_l=3, batch_size=256):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    for i in tqdm(range(0, len(X_np), batch_size), desc=\"Predicting test\", leave=False):\n",
    "        xb = torch.tensor(X_np[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        probs = torch.sigmoid(model(xb)).detach().cpu().numpy()\n",
    "\n",
    "        for p in probs:\n",
    "            idx = np.argsort(p)[::-1]\n",
    "            chosen = [j for j in idx[:50] if p[j] >= thr]\n",
    "            if len(chosen) < min_l:\n",
    "                chosen = idx[:min_l].tolist()\n",
    "            chosen = chosen[:max_l]\n",
    "            chosen = sorted(map(int, chosen))\n",
    "            all_labels.append(\",\".join(map(str, chosen)))\n",
    "    return all_labels\n",
    "\n",
    "pred_strs = predict_test_labels_rule(\n",
    "    model, X_test, device=device,\n",
    "    thr=THR, min_l=MIN_LABELS, max_l=MAX_LABELS,\n",
    "    batch_size=256\n",
    ")\n",
    "\n",
    "sub = pd.DataFrame({\"id\": test_ids, \"labels\": pred_strs})\n",
    "SUB_PATH = os.path.join(ART_DIR, f\"submission_attn_{model.mode}.csv\")\n",
    "sub.to_csv(SUB_PATH, index=False)\n",
    "print(\"✅ Saved submission:\", SUB_PATH)\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e2527-7d60-40b2-8ce7-b29ad833030e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816fb0b-2174-4292-b13f-247f964afca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe117078-2970-4f89-91ec-69b5688d4769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCI Environment (Python 3.9)",
   "language": "python",
   "name": "esci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
